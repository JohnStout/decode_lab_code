{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNMF-E demo pipeline: Intro \n",
    "This notebook demonstrates how to use Caiman for processing 1p microendoscopic data. It shows how to use Caiman for the following steps:\n",
    "\n",
    "![cnmfe pipeline full](https://raw.githubusercontent.com/EricThomson/image_sandbox/main/images/full_cnmfe_workflow.jpg)\n",
    "\n",
    "1. Apply the NoRMCorre (nonrigid motion correction) algorithm for motion correction.\n",
    "2. Apply the constrained nonnegative matrix factorization endoscopic (CNMF-E) source separation algorithm to extract an initial estimate of neuronal spatial footprint and calcium traces.\n",
    "3. Apply quality control metrics to evaluate the initial estimates, and narrow down to the final set of estimates.\n",
    "\n",
    "Some tools for visualization of movies and results are also included. \n",
    "\n",
    "> This demo follows a similar pattern to the CNMF demo in `demo_pipeline.ipynb`. It includes less explanation except where there are important differences. If you want to get a more explanation-heavy picture of the fundamentals, we suggest starting with `demo_pipeline.ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and general setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "    <style>\n",
       "        .bk-notebook-logo {\n",
       "            display: block;\n",
       "            width: 20px;\n",
       "            height: 20px;\n",
       "            background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABx0RVh0U29mdHdhcmUAQWRvYmUgRmlyZXdvcmtzIENTNui8sowAAAOkSURBVDiNjZRtaJVlGMd/1/08zzln5zjP1LWcU9N0NkN8m2CYjpgQYQXqSs0I84OLIC0hkEKoPtiH3gmKoiJDU7QpLgoLjLIQCpEsNJ1vqUOdO7ppbuec5+V+rj4ctwzd8IIbbi6u+8f1539dt3A78eXC7QizUF7gyV1fD1Yqg4JWz84yffhm0qkFqBogB9rM8tZdtwVsPUhWhGcFJngGeWrPzHm5oaMmkfEg1usvLFyc8jLRqDOMru7AyC8saQr7GG7f5fvDeH7Ej8CM66nIF+8yngt6HWaKh7k49Soy9nXurCi1o3qUbS3zWfrYeQDTB/Qj6kX6Ybhw4B+bOYoLKCC9H3Nu/leUTZ1JdRWkkn2ldcCamzrcf47KKXdAJllSlxAOkRgyHsGC/zRday5Qld9DyoM4/q/rUoy/CXh3jzOu3bHUVZeU+DEn8FInkPBFlu3+nW3Nw0mk6vCDiWg8CeJaxEwuHS3+z5RgY+YBR6V1Z1nxSOfoaPa4LASWxxdNp+VWTk7+4vzaou8v8PN+xo+KY2xsw6une2frhw05CTYOmQvsEhjhWjn0bmXPjpE1+kplmmkP3suftwTubK9Vq22qKmrBhpY4jvd5afdRA3wGjFAgcnTK2s4hY0/GPNIb0nErGMCRxWOOX64Z8RAC4oCXdklmEvcL8o0BfkNK4lUg9HTl+oPlQxdNo3Mg4Nv175e/1LDGzZen30MEjRUtmXSfiTVu1kK8W4txyV6BMKlbgk3lMwYCiusNy9fVfvvwMxv8Ynl6vxoByANLTWplvuj/nF9m2+PDtt1eiHPBr1oIfhCChQMBw6Aw0UulqTKZdfVvfG7VcfIqLG9bcldL/+pdWTLxLUy8Qq38heUIjh4XlzZxzQm19lLFlr8vdQ97rjZVOLf8nclzckbcD4wxXMidpX30sFd37Fv/GtwwhzhxGVAprjbg0gCAEeIgwCZyTV2Z1REEW8O4py0wsjeloKoMr6iCY6dP92H6Vw/oTyICIthibxjm/DfN9lVz8IqtqKYLUXfoKVMVQVVJOElGjrnnUt9T9wbgp8AyYKaGlqingHZU/uG2NTZSVqwHQTWkx9hxjkpWDaCg6Ckj5qebgBVbT3V3NNXMSiWSDdGV3hrtzla7J+duwPOToIg42ChPQOQjspnSlp1V+Gjdged7+8UN5CRAV7a5EdFNwCjEaBR27b3W890TE7g24NAP/mMDXRWrGoFPQI9ls/MWO2dWFAar/xcOIImbbpA3zgAAAABJRU5ErkJggg==);\n",
       "        }\n",
       "    </style>\n",
       "    <div>\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-notebook-logo\"></a>\n",
       "        <span id=\"c916770d-dfbb-4594-a6d3-8567d2f7efdc\">Loading BokehJS ...</span>\n",
       "    </div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  const force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "const JS_MIME_TYPE = 'application/javascript';\n",
       "  const HTML_MIME_TYPE = 'text/html';\n",
       "  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  const CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    const script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    function drop(id) {\n",
       "      const view = Bokeh.index.get_by_id(id)\n",
       "      if (view != null) {\n",
       "        view.model.document.clear()\n",
       "        Bokeh.index.delete(view)\n",
       "      }\n",
       "    }\n",
       "\n",
       "    const cell = handle.cell;\n",
       "\n",
       "    const id = cell.output_area._bokeh_element_id;\n",
       "    const server_id = cell.output_area._bokeh_server_id;\n",
       "\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null) {\n",
       "      drop(id)\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd_clean, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            const id = msg.content.text.trim()\n",
       "            drop(id)\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd_destroy);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    const output_area = handle.output_area;\n",
       "    const output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      const bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      const script_attrs = bk_div.children[0].attributes;\n",
       "      for (let i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      const toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    const events = require('base/js/events');\n",
       "    const OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  const NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    const el = document.getElementById(\"c916770d-dfbb-4594-a6d3-8567d2f7efdc\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error(url) {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < css_urls.length; i++) {\n",
       "      const url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < js_urls.length; i++) {\n",
       "      const url = js_urls[i];\n",
       "      const element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.3.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.3.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.3.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.3.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.3.2.min.js\", \"https://unpkg.com/@holoviz/panel@1.3.4/dist/panel.min.js\"];\n",
       "  const css_urls = [];\n",
       "\n",
       "  const inline_js = [    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "function(Bokeh) {\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "          for (let i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      const cell = $(document.getElementById(\"c916770d-dfbb-4594-a6d3-8567d2f7efdc\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    const el = document.getElementById(\"c916770d-dfbb-4594-a6d3-8567d2f7efdc\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.3.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.3.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.3.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.3.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.3.2.min.js\", \"https://unpkg.com/@holoviz/panel@1.3.4/dist/panel.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n          for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\nif (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"c916770d-dfbb-4594-a6d3-8567d2f7efdc\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "  var py_version = '3.3.2'.replace('rc', '-rc.').replace('.dev', '-dev.');\n",
       "  var reloading = false;\n",
       "  var Bokeh = root.Bokeh;\n",
       "\n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks;\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "    if (js_modules == null) js_modules = [];\n",
       "    if (js_exports == null) js_exports = {};\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    if (!reloading) {\n",
       "      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    }\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "    window._bokeh_on_load = on_load\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    var skip = [];\n",
       "    if (window.requirejs) {\n",
       "      window.requirejs.config({'packages': {}, 'paths': {'jspanel': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/jspanel', 'jspanel-modal': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal', 'jspanel-tooltip': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip', 'jspanel-hint': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint', 'jspanel-layout': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout', 'jspanel-contextmenu': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu', 'jspanel-dock': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock', 'gridstack': 'https://cdn.jsdelivr.net/npm/gridstack@7.2.3/dist/gridstack-all', 'notyf': 'https://cdn.jsdelivr.net/npm/notyf@3/notyf.min'}, 'shim': {'jspanel': {'exports': 'jsPanel'}, 'gridstack': {'exports': 'GridStack'}}});\n",
       "      require([\"jspanel\"], function(jsPanel) {\n",
       "\twindow.jsPanel = jsPanel\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-modal\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-tooltip\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-hint\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-layout\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-contextmenu\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"jspanel-dock\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"gridstack\"], function(GridStack) {\n",
       "\twindow.GridStack = GridStack\n",
       "\ton_load()\n",
       "      })\n",
       "      require([\"notyf\"], function() {\n",
       "\ton_load()\n",
       "      })\n",
       "      root._bokeh_is_loading = css_urls.length + 9;\n",
       "    } else {\n",
       "      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n",
       "    }\n",
       "\n",
       "    var existing_stylesheets = []\n",
       "    var links = document.getElementsByTagName('link')\n",
       "    for (var i = 0; i < links.length; i++) {\n",
       "      var link = links[i]\n",
       "      if (link.href != null) {\n",
       "\texisting_stylesheets.push(link.href)\n",
       "      }\n",
       "    }\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      if (existing_stylesheets.indexOf(url) !== -1) {\n",
       "\ton_load()\n",
       "\tcontinue;\n",
       "      }\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }    if (((window['jsPanel'] !== undefined) && (!(window['jsPanel'] instanceof HTMLElement))) || window.requirejs) {\n",
       "      var urls = ['https://cdn.holoviz.org/panel/1.3.4/dist/bundled/floatpanel/jspanel4@4.12.0/dist/jspanel.js', 'https://cdn.holoviz.org/panel/1.3.4/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal.js', 'https://cdn.holoviz.org/panel/1.3.4/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip.js', 'https://cdn.holoviz.org/panel/1.3.4/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint.js', 'https://cdn.holoviz.org/panel/1.3.4/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout.js', 'https://cdn.holoviz.org/panel/1.3.4/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu.js', 'https://cdn.holoviz.org/panel/1.3.4/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock.js'];\n",
       "      for (var i = 0; i < urls.length; i++) {\n",
       "        skip.push(urls[i])\n",
       "      }\n",
       "    }    if (((window['GridStack'] !== undefined) && (!(window['GridStack'] instanceof HTMLElement))) || window.requirejs) {\n",
       "      var urls = ['https://cdn.holoviz.org/panel/1.3.4/dist/bundled/gridstack/gridstack@7.2.3/dist/gridstack-all.js'];\n",
       "      for (var i = 0; i < urls.length; i++) {\n",
       "        skip.push(urls[i])\n",
       "      }\n",
       "    }    if (((window['Notyf'] !== undefined) && (!(window['Notyf'] instanceof HTMLElement))) || window.requirejs) {\n",
       "      var urls = ['https://cdn.holoviz.org/panel/1.3.4/dist/bundled/notificationarea/notyf@3/notyf.min.js'];\n",
       "      for (var i = 0; i < urls.length; i++) {\n",
       "        skip.push(urls[i])\n",
       "      }\n",
       "    }    var existing_scripts = []\n",
       "    var scripts = document.getElementsByTagName('script')\n",
       "    for (var i = 0; i < scripts.length; i++) {\n",
       "      var script = scripts[i]\n",
       "      if (script.src != null) {\n",
       "\texisting_scripts.push(script.src)\n",
       "      }\n",
       "    }\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    for (var i = 0; i < js_modules.length; i++) {\n",
       "      var url = js_modules[i];\n",
       "      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      element.type = \"module\";\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    for (const name in js_exports) {\n",
       "      var url = js_exports[name];\n",
       "      if (skip.indexOf(url) >= 0 || root[name] != null) {\n",
       "\tif (!window.requirejs) {\n",
       "\t  on_load();\n",
       "\t}\n",
       "\tcontinue;\n",
       "      }\n",
       "      var element = document.createElement('script');\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.type = \"module\";\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      element.textContent = `\n",
       "      import ${name} from \"${url}\"\n",
       "      window.${name} = ${name}\n",
       "      window._bokeh_on_load()\n",
       "      `\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "    if (!js_urls.length && !js_modules.length) {\n",
       "      on_load()\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.3.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.3.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.3.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.3.2.min.js\", \"https://cdn.holoviz.org/panel/1.3.4/dist/panel.min.js\"];\n",
       "  var js_modules = [];\n",
       "  var js_exports = {};\n",
       "  var css_urls = [];\n",
       "  var inline_js = [    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "function(Bokeh) {} // ensure no trailing comma for IE\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "\ttry {\n",
       "          inline_js[i].call(root, root.Bokeh);\n",
       "\t} catch(e) {\n",
       "\t  if (!reloading) {\n",
       "\t    throw e;\n",
       "\t  }\n",
       "\t}\n",
       "      }\n",
       "      // Cache old bokeh versions\n",
       "      if (Bokeh != undefined && !reloading) {\n",
       "\tvar NewBokeh = root.Bokeh;\n",
       "\tif (Bokeh.versions === undefined) {\n",
       "\t  Bokeh.versions = new Map();\n",
       "\t}\n",
       "\tif (NewBokeh.version !== Bokeh.version) {\n",
       "\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n",
       "\t}\n",
       "\troot.Bokeh = Bokeh;\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    }\n",
       "    root._bokeh_is_initializing = false\n",
       "  }\n",
       "\n",
       "  function load_or_wait() {\n",
       "    // Implement a backoff loop that tries to ensure we do not load multiple\n",
       "    // versions of Bokeh and its dependencies at the same time.\n",
       "    // In recent versions we use the root._bokeh_is_initializing flag\n",
       "    // to determine whether there is an ongoing attempt to initialize\n",
       "    // bokeh, however for backward compatibility we also try to ensure\n",
       "    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n",
       "    // before older versions are fully initialized.\n",
       "    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n",
       "      root._bokeh_is_initializing = false;\n",
       "      root._bokeh_onload_callbacks = undefined;\n",
       "      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n",
       "      load_or_wait();\n",
       "    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n",
       "      setTimeout(load_or_wait, 100);\n",
       "    } else {\n",
       "      root._bokeh_is_initializing = true\n",
       "      root._bokeh_onload_callbacks = []\n",
       "      var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n",
       "      if (!reloading && !bokeh_loaded) {\n",
       "\troot.Bokeh = undefined;\n",
       "      }\n",
       "      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n",
       "\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "\trun_inline_js();\n",
       "      });\n",
       "    }\n",
       "  }\n",
       "  // Give older versions of the autoload script a head-start to ensure\n",
       "  // they initialize before we start loading newer version.\n",
       "  setTimeout(load_or_wait, 100)\n",
       "}(window));"
      ],
      "application/vnd.holoviews_load.v0+json": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n  var py_version = '3.3.2'.replace('rc', '-rc.').replace('.dev', '-dev.');\n  var reloading = false;\n  var Bokeh = root.Bokeh;\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks;\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, js_modules, js_exports, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n    if (js_modules == null) js_modules = [];\n    if (js_exports == null) js_exports = {};\n\n    root._bokeh_onload_callbacks.push(callback);\n\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls.length === 0 && js_modules.length === 0 && Object.keys(js_exports).length === 0) {\n      run_callbacks();\n      return null;\n    }\n    if (!reloading) {\n      console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    }\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n    window._bokeh_on_load = on_load\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    var skip = [];\n    if (window.requirejs) {\n      window.requirejs.config({'packages': {}, 'paths': {'jspanel': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/jspanel', 'jspanel-modal': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal', 'jspanel-tooltip': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip', 'jspanel-hint': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint', 'jspanel-layout': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout', 'jspanel-contextmenu': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu', 'jspanel-dock': 'https://cdn.jsdelivr.net/npm/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock', 'gridstack': 'https://cdn.jsdelivr.net/npm/gridstack@7.2.3/dist/gridstack-all', 'notyf': 'https://cdn.jsdelivr.net/npm/notyf@3/notyf.min'}, 'shim': {'jspanel': {'exports': 'jsPanel'}, 'gridstack': {'exports': 'GridStack'}}});\n      require([\"jspanel\"], function(jsPanel) {\n\twindow.jsPanel = jsPanel\n\ton_load()\n      })\n      require([\"jspanel-modal\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-tooltip\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-hint\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-layout\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-contextmenu\"], function() {\n\ton_load()\n      })\n      require([\"jspanel-dock\"], function() {\n\ton_load()\n      })\n      require([\"gridstack\"], function(GridStack) {\n\twindow.GridStack = GridStack\n\ton_load()\n      })\n      require([\"notyf\"], function() {\n\ton_load()\n      })\n      root._bokeh_is_loading = css_urls.length + 9;\n    } else {\n      root._bokeh_is_loading = css_urls.length + js_urls.length + js_modules.length + Object.keys(js_exports).length;\n    }\n\n    var existing_stylesheets = []\n    var links = document.getElementsByTagName('link')\n    for (var i = 0; i < links.length; i++) {\n      var link = links[i]\n      if (link.href != null) {\n\texisting_stylesheets.push(link.href)\n      }\n    }\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      if (existing_stylesheets.indexOf(url) !== -1) {\n\ton_load()\n\tcontinue;\n      }\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }    if (((window['jsPanel'] !== undefined) && (!(window['jsPanel'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.3.4/dist/bundled/floatpanel/jspanel4@4.12.0/dist/jspanel.js', 'https://cdn.holoviz.org/panel/1.3.4/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/modal/jspanel.modal.js', 'https://cdn.holoviz.org/panel/1.3.4/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/tooltip/jspanel.tooltip.js', 'https://cdn.holoviz.org/panel/1.3.4/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/hint/jspanel.hint.js', 'https://cdn.holoviz.org/panel/1.3.4/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/layout/jspanel.layout.js', 'https://cdn.holoviz.org/panel/1.3.4/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/contextmenu/jspanel.contextmenu.js', 'https://cdn.holoviz.org/panel/1.3.4/dist/bundled/floatpanel/jspanel4@4.12.0/dist/extensions/dock/jspanel.dock.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['GridStack'] !== undefined) && (!(window['GridStack'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.3.4/dist/bundled/gridstack/gridstack@7.2.3/dist/gridstack-all.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    if (((window['Notyf'] !== undefined) && (!(window['Notyf'] instanceof HTMLElement))) || window.requirejs) {\n      var urls = ['https://cdn.holoviz.org/panel/1.3.4/dist/bundled/notificationarea/notyf@3/notyf.min.js'];\n      for (var i = 0; i < urls.length; i++) {\n        skip.push(urls[i])\n      }\n    }    var existing_scripts = []\n    var scripts = document.getElementsByTagName('script')\n    for (var i = 0; i < scripts.length; i++) {\n      var script = scripts[i]\n      if (script.src != null) {\n\texisting_scripts.push(script.src)\n      }\n    }\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (var i = 0; i < js_modules.length; i++) {\n      var url = js_modules[i];\n      if (skip.indexOf(url) !== -1 || existing_scripts.indexOf(url) !== -1) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n    for (const name in js_exports) {\n      var url = js_exports[name];\n      if (skip.indexOf(url) >= 0 || root[name] != null) {\n\tif (!window.requirejs) {\n\t  on_load();\n\t}\n\tcontinue;\n      }\n      var element = document.createElement('script');\n      element.onerror = on_error;\n      element.async = false;\n      element.type = \"module\";\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      element.textContent = `\n      import ${name} from \"${url}\"\n      window.${name} = ${name}\n      window._bokeh_on_load()\n      `\n      document.head.appendChild(element);\n    }\n    if (!js_urls.length && !js_modules.length) {\n      on_load()\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.3.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.3.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.3.2.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.3.2.min.js\", \"https://cdn.holoviz.org/panel/1.3.4/dist/panel.min.js\"];\n  var js_modules = [];\n  var js_exports = {};\n  var css_urls = [];\n  var inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n\ttry {\n          inline_js[i].call(root, root.Bokeh);\n\t} catch(e) {\n\t  if (!reloading) {\n\t    throw e;\n\t  }\n\t}\n      }\n      // Cache old bokeh versions\n      if (Bokeh != undefined && !reloading) {\n\tvar NewBokeh = root.Bokeh;\n\tif (Bokeh.versions === undefined) {\n\t  Bokeh.versions = new Map();\n\t}\n\tif (NewBokeh.version !== Bokeh.version) {\n\t  Bokeh.versions.set(NewBokeh.version, NewBokeh)\n\t}\n\troot.Bokeh = Bokeh;\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    }\n    root._bokeh_is_initializing = false\n  }\n\n  function load_or_wait() {\n    // Implement a backoff loop that tries to ensure we do not load multiple\n    // versions of Bokeh and its dependencies at the same time.\n    // In recent versions we use the root._bokeh_is_initializing flag\n    // to determine whether there is an ongoing attempt to initialize\n    // bokeh, however for backward compatibility we also try to ensure\n    // that we do not start loading a newer (Panel>=1.0 and Bokeh>3) version\n    // before older versions are fully initialized.\n    if (root._bokeh_is_initializing && Date.now() > root._bokeh_timeout) {\n      root._bokeh_is_initializing = false;\n      root._bokeh_onload_callbacks = undefined;\n      console.log(\"Bokeh: BokehJS was loaded multiple times but one version failed to initialize.\");\n      load_or_wait();\n    } else if (root._bokeh_is_initializing || (typeof root._bokeh_is_initializing === \"undefined\" && root._bokeh_onload_callbacks !== undefined)) {\n      setTimeout(load_or_wait, 100);\n    } else {\n      root._bokeh_is_initializing = true\n      root._bokeh_onload_callbacks = []\n      var bokeh_loaded = Bokeh != null && (Bokeh.version === py_version || (Bokeh.versions !== undefined && Bokeh.versions.has(py_version)));\n      if (!reloading && !bokeh_loaded) {\n\troot.Bokeh = undefined;\n      }\n      load_libs(css_urls, js_urls, js_modules, js_exports, function() {\n\tconsole.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n\trun_inline_js();\n      });\n    }\n  }\n  // Give older versions of the autoload script a head-start to ensure\n  // they initialize before we start loading newer version.\n  setTimeout(load_or_wait, 100)\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "if ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n",
       "  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n",
       "}\n",
       "\n",
       "\n",
       "    function JupyterCommManager() {\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n",
       "      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        comm_manager.register_target(comm_id, function(comm) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        });\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        });\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n",
       "          var messages = comm.messages[Symbol.asyncIterator]();\n",
       "          function processIteratorResult(result) {\n",
       "            var message = result.value;\n",
       "            console.log(message)\n",
       "            var content = {data: message.data, comm_id};\n",
       "            var buffers = []\n",
       "            for (var buffer of message.buffers || []) {\n",
       "              buffers.push(new DataView(buffer))\n",
       "            }\n",
       "            var metadata = message.metadata || {};\n",
       "            var msg = {content, buffers, metadata}\n",
       "            msg_handler(msg);\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "          return messages.next().then(processIteratorResult);\n",
       "        })\n",
       "      }\n",
       "    }\n",
       "\n",
       "    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n",
       "      if (comm_id in window.PyViz.comms) {\n",
       "        return window.PyViz.comms[comm_id];\n",
       "      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n",
       "        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n",
       "        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n",
       "        if (msg_handler) {\n",
       "          comm.on_msg(msg_handler);\n",
       "        }\n",
       "      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n",
       "        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n",
       "        comm.open();\n",
       "        if (msg_handler) {\n",
       "          comm.onMsg = msg_handler;\n",
       "        }\n",
       "      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n",
       "        var comm_promise = google.colab.kernel.comms.open(comm_id)\n",
       "        comm_promise.then((comm) => {\n",
       "          window.PyViz.comms[comm_id] = comm;\n",
       "          if (msg_handler) {\n",
       "            var messages = comm.messages[Symbol.asyncIterator]();\n",
       "            function processIteratorResult(result) {\n",
       "              var message = result.value;\n",
       "              var content = {data: message.data};\n",
       "              var metadata = message.metadata || {comm_id};\n",
       "              var msg = {content, metadata}\n",
       "              msg_handler(msg);\n",
       "              return messages.next().then(processIteratorResult);\n",
       "            }\n",
       "            return messages.next().then(processIteratorResult);\n",
       "          }\n",
       "        }) \n",
       "        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n",
       "          return comm_promise.then((comm) => {\n",
       "            comm.send(data, metadata, buffers, disposeOnDone);\n",
       "          });\n",
       "        };\n",
       "        var comm = {\n",
       "          send: sendClosure\n",
       "        };\n",
       "      }\n",
       "      window.PyViz.comms[comm_id] = comm;\n",
       "      return comm;\n",
       "    }\n",
       "    window.PyViz.comm_manager = new JupyterCommManager();\n",
       "    \n",
       "\n",
       "\n",
       "var JS_MIME_TYPE = 'application/javascript';\n",
       "var HTML_MIME_TYPE = 'text/html';\n",
       "var EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\n",
       "var CLASS_NAME = 'output';\n",
       "\n",
       "/**\n",
       " * Render data to the DOM node\n",
       " */\n",
       "function render(props, node) {\n",
       "  var div = document.createElement(\"div\");\n",
       "  var script = document.createElement(\"script\");\n",
       "  node.appendChild(div);\n",
       "  node.appendChild(script);\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when a new output is added\n",
       " */\n",
       "function handle_add_output(event, handle) {\n",
       "  var output_area = handle.output_area;\n",
       "  var output = handle.output;\n",
       "  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "    return\n",
       "  }\n",
       "  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "  if (id !== undefined) {\n",
       "    var nchildren = toinsert.length;\n",
       "    var html_node = toinsert[nchildren-1].children[0];\n",
       "    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var scripts = [];\n",
       "    var nodelist = html_node.querySelectorAll(\"script\");\n",
       "    for (var i in nodelist) {\n",
       "      if (nodelist.hasOwnProperty(i)) {\n",
       "        scripts.push(nodelist[i])\n",
       "      }\n",
       "    }\n",
       "\n",
       "    scripts.forEach( function (oldScript) {\n",
       "      var newScript = document.createElement(\"script\");\n",
       "      var attrs = [];\n",
       "      var nodemap = oldScript.attributes;\n",
       "      for (var j in nodemap) {\n",
       "        if (nodemap.hasOwnProperty(j)) {\n",
       "          attrs.push(nodemap[j])\n",
       "        }\n",
       "      }\n",
       "      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n",
       "      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n",
       "      oldScript.parentNode.replaceChild(newScript, oldScript);\n",
       "    });\n",
       "    if (JS_MIME_TYPE in output.data) {\n",
       "      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n",
       "    }\n",
       "    output_area._hv_plot_id = id;\n",
       "    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n",
       "      window.PyViz.plot_index[id] = Bokeh.index[id];\n",
       "    } else {\n",
       "      window.PyViz.plot_index[id] = null;\n",
       "    }\n",
       "  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "    var bk_div = document.createElement(\"div\");\n",
       "    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "    var script_attrs = bk_div.children[0].attributes;\n",
       "    for (var i = 0; i < script_attrs.length; i++) {\n",
       "      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "    }\n",
       "    // store reference to server id on output_area\n",
       "    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle when an output is cleared or removed\n",
       " */\n",
       "function handle_clear_output(event, handle) {\n",
       "  var id = handle.cell.output_area._hv_plot_id;\n",
       "  var server_id = handle.cell.output_area._bokeh_server_id;\n",
       "  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n",
       "  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n",
       "  if (server_id !== null) {\n",
       "    comm.send({event_type: 'server_delete', 'id': server_id});\n",
       "    return;\n",
       "  } else if (comm !== null) {\n",
       "    comm.send({event_type: 'delete', 'id': id});\n",
       "  }\n",
       "  delete PyViz.plot_index[id];\n",
       "  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n",
       "    var doc = window.Bokeh.index[id].model.document\n",
       "    doc.clear();\n",
       "    const i = window.Bokeh.documents.indexOf(doc);\n",
       "    if (i > -1) {\n",
       "      window.Bokeh.documents.splice(i, 1);\n",
       "    }\n",
       "  }\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle kernel restart event\n",
       " */\n",
       "function handle_kernel_cleanup(event, handle) {\n",
       "  delete PyViz.comms[\"hv-extension-comm\"];\n",
       "  window.PyViz.plot_index = {}\n",
       "}\n",
       "\n",
       "/**\n",
       " * Handle update_display_data messages\n",
       " */\n",
       "function handle_update_output(event, handle) {\n",
       "  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n",
       "  handle_add_output(event, handle)\n",
       "}\n",
       "\n",
       "function register_renderer(events, OutputArea) {\n",
       "  function append_mime(data, metadata, element) {\n",
       "    // create a DOM node to render to\n",
       "    var toinsert = this.create_output_subarea(\n",
       "    metadata,\n",
       "    CLASS_NAME,\n",
       "    EXEC_MIME_TYPE\n",
       "    );\n",
       "    this.keyboard_manager.register_events(toinsert);\n",
       "    // Render to node\n",
       "    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "    render(props, toinsert[0]);\n",
       "    element.append(toinsert);\n",
       "    return toinsert\n",
       "  }\n",
       "\n",
       "  events.on('output_added.OutputArea', handle_add_output);\n",
       "  events.on('output_updated.OutputArea', handle_update_output);\n",
       "  events.on('clear_output.CodeCell', handle_clear_output);\n",
       "  events.on('delete.Cell', handle_clear_output);\n",
       "  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n",
       "\n",
       "  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "    safe: true,\n",
       "    index: 0\n",
       "  });\n",
       "}\n",
       "\n",
       "if (window.Jupyter !== undefined) {\n",
       "  try {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  } catch(err) {\n",
       "  }\n",
       "}\n"
      ],
      "application/vnd.holoviews_load.v0+json": "\nif ((window.PyViz === undefined) || (window.PyViz instanceof HTMLElement)) {\n  window.PyViz = {comms: {}, comm_status:{}, kernels:{}, receivers: {}, plot_index: []}\n}\n\n\n    function JupyterCommManager() {\n    }\n\n    JupyterCommManager.prototype.register_target = function(plot_id, comm_id, msg_handler) {\n      if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        comm_manager.register_target(comm_id, function(comm) {\n          comm.on_msg(msg_handler);\n        });\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        window.PyViz.kernels[plot_id].registerCommTarget(comm_id, function(comm) {\n          comm.onMsg = msg_handler;\n        });\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        google.colab.kernel.comms.registerTarget(comm_id, (comm) => {\n          var messages = comm.messages[Symbol.asyncIterator]();\n          function processIteratorResult(result) {\n            var message = result.value;\n            console.log(message)\n            var content = {data: message.data, comm_id};\n            var buffers = []\n            for (var buffer of message.buffers || []) {\n              buffers.push(new DataView(buffer))\n            }\n            var metadata = message.metadata || {};\n            var msg = {content, buffers, metadata}\n            msg_handler(msg);\n            return messages.next().then(processIteratorResult);\n          }\n          return messages.next().then(processIteratorResult);\n        })\n      }\n    }\n\n    JupyterCommManager.prototype.get_client_comm = function(plot_id, comm_id, msg_handler) {\n      if (comm_id in window.PyViz.comms) {\n        return window.PyViz.comms[comm_id];\n      } else if (window.comm_manager || ((window.Jupyter !== undefined) && (Jupyter.notebook.kernel != null))) {\n        var comm_manager = window.comm_manager || Jupyter.notebook.kernel.comm_manager;\n        var comm = comm_manager.new_comm(comm_id, {}, {}, {}, comm_id);\n        if (msg_handler) {\n          comm.on_msg(msg_handler);\n        }\n      } else if ((plot_id in window.PyViz.kernels) && (window.PyViz.kernels[plot_id])) {\n        var comm = window.PyViz.kernels[plot_id].connectToComm(comm_id);\n        comm.open();\n        if (msg_handler) {\n          comm.onMsg = msg_handler;\n        }\n      } else if (typeof google != 'undefined' && google.colab.kernel != null) {\n        var comm_promise = google.colab.kernel.comms.open(comm_id)\n        comm_promise.then((comm) => {\n          window.PyViz.comms[comm_id] = comm;\n          if (msg_handler) {\n            var messages = comm.messages[Symbol.asyncIterator]();\n            function processIteratorResult(result) {\n              var message = result.value;\n              var content = {data: message.data};\n              var metadata = message.metadata || {comm_id};\n              var msg = {content, metadata}\n              msg_handler(msg);\n              return messages.next().then(processIteratorResult);\n            }\n            return messages.next().then(processIteratorResult);\n          }\n        }) \n        var sendClosure = (data, metadata, buffers, disposeOnDone) => {\n          return comm_promise.then((comm) => {\n            comm.send(data, metadata, buffers, disposeOnDone);\n          });\n        };\n        var comm = {\n          send: sendClosure\n        };\n      }\n      window.PyViz.comms[comm_id] = comm;\n      return comm;\n    }\n    window.PyViz.comm_manager = new JupyterCommManager();\n    \n\n\nvar JS_MIME_TYPE = 'application/javascript';\nvar HTML_MIME_TYPE = 'text/html';\nvar EXEC_MIME_TYPE = 'application/vnd.holoviews_exec.v0+json';\nvar CLASS_NAME = 'output';\n\n/**\n * Render data to the DOM node\n */\nfunction render(props, node) {\n  var div = document.createElement(\"div\");\n  var script = document.createElement(\"script\");\n  node.appendChild(div);\n  node.appendChild(script);\n}\n\n/**\n * Handle when a new output is added\n */\nfunction handle_add_output(event, handle) {\n  var output_area = handle.output_area;\n  var output = handle.output;\n  if ((output.data == undefined) || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n    return\n  }\n  var id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n  var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n  if (id !== undefined) {\n    var nchildren = toinsert.length;\n    var html_node = toinsert[nchildren-1].children[0];\n    html_node.innerHTML = output.data[HTML_MIME_TYPE];\n    var scripts = [];\n    var nodelist = html_node.querySelectorAll(\"script\");\n    for (var i in nodelist) {\n      if (nodelist.hasOwnProperty(i)) {\n        scripts.push(nodelist[i])\n      }\n    }\n\n    scripts.forEach( function (oldScript) {\n      var newScript = document.createElement(\"script\");\n      var attrs = [];\n      var nodemap = oldScript.attributes;\n      for (var j in nodemap) {\n        if (nodemap.hasOwnProperty(j)) {\n          attrs.push(nodemap[j])\n        }\n      }\n      attrs.forEach(function(attr) { newScript.setAttribute(attr.name, attr.value) });\n      newScript.appendChild(document.createTextNode(oldScript.innerHTML));\n      oldScript.parentNode.replaceChild(newScript, oldScript);\n    });\n    if (JS_MIME_TYPE in output.data) {\n      toinsert[nchildren-1].children[1].textContent = output.data[JS_MIME_TYPE];\n    }\n    output_area._hv_plot_id = id;\n    if ((window.Bokeh !== undefined) && (id in Bokeh.index)) {\n      window.PyViz.plot_index[id] = Bokeh.index[id];\n    } else {\n      window.PyViz.plot_index[id] = null;\n    }\n  } else if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n    var bk_div = document.createElement(\"div\");\n    bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n    var script_attrs = bk_div.children[0].attributes;\n    for (var i = 0; i < script_attrs.length; i++) {\n      toinsert[toinsert.length - 1].childNodes[1].setAttribute(script_attrs[i].name, script_attrs[i].value);\n    }\n    // store reference to server id on output_area\n    output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n  }\n}\n\n/**\n * Handle when an output is cleared or removed\n */\nfunction handle_clear_output(event, handle) {\n  var id = handle.cell.output_area._hv_plot_id;\n  var server_id = handle.cell.output_area._bokeh_server_id;\n  if (((id === undefined) || !(id in PyViz.plot_index)) && (server_id !== undefined)) { return; }\n  var comm = window.PyViz.comm_manager.get_client_comm(\"hv-extension-comm\", \"hv-extension-comm\", function () {});\n  if (server_id !== null) {\n    comm.send({event_type: 'server_delete', 'id': server_id});\n    return;\n  } else if (comm !== null) {\n    comm.send({event_type: 'delete', 'id': id});\n  }\n  delete PyViz.plot_index[id];\n  if ((window.Bokeh !== undefined) & (id in window.Bokeh.index)) {\n    var doc = window.Bokeh.index[id].model.document\n    doc.clear();\n    const i = window.Bokeh.documents.indexOf(doc);\n    if (i > -1) {\n      window.Bokeh.documents.splice(i, 1);\n    }\n  }\n}\n\n/**\n * Handle kernel restart event\n */\nfunction handle_kernel_cleanup(event, handle) {\n  delete PyViz.comms[\"hv-extension-comm\"];\n  window.PyViz.plot_index = {}\n}\n\n/**\n * Handle update_display_data messages\n */\nfunction handle_update_output(event, handle) {\n  handle_clear_output(event, {cell: {output_area: handle.output_area}})\n  handle_add_output(event, handle)\n}\n\nfunction register_renderer(events, OutputArea) {\n  function append_mime(data, metadata, element) {\n    // create a DOM node to render to\n    var toinsert = this.create_output_subarea(\n    metadata,\n    CLASS_NAME,\n    EXEC_MIME_TYPE\n    );\n    this.keyboard_manager.register_events(toinsert);\n    // Render to node\n    var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n    render(props, toinsert[0]);\n    element.append(toinsert);\n    return toinsert\n  }\n\n  events.on('output_added.OutputArea', handle_add_output);\n  events.on('output_updated.OutputArea', handle_update_output);\n  events.on('clear_output.CodeCell', handle_clear_output);\n  events.on('delete.Cell', handle_clear_output);\n  events.on('kernel_ready.Kernel', handle_kernel_cleanup);\n\n  OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n    safe: true,\n    index: 0\n  });\n}\n\nif (window.Jupyter !== undefined) {\n  try {\n    var events = require('base/js/events');\n    var OutputArea = require('notebook/js/outputarea').OutputArea;\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  } catch(err) {\n  }\n}\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>*[data-root-id],\n",
       "*[data-root-id] > * {\n",
       "  box-sizing: border-box;\n",
       "  font-family: var(--jp-ui-font-family);\n",
       "  font-size: var(--jp-ui-font-size1);\n",
       "  color: var(--vscode-editor-foreground, var(--jp-ui-font-color1));\n",
       "}\n",
       "\n",
       "/* Override VSCode background color */\n",
       ".cell-output-ipywidget-background:has(\n",
       "    > .cell-output-ipywidget-background > .lm-Widget > *[data-root-id]\n",
       "  ),\n",
       ".cell-output-ipywidget-background:has(> .lm-Widget > *[data-root-id]) {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "</style>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.holoviews_exec.v0+json": "",
      "text/html": [
       "<div id='p1004'>\n",
       "  <div id=\"e66d5396-573c-4ba6-ba4c-3336a87e21c8\" data-root-id=\"p1004\" style=\"display: contents;\"></div>\n",
       "</div>\n",
       "<script type=\"application/javascript\">(function(root) {\n",
       "  var docs_json = {\"d712383a-8706-4e4e-91f6-c8407566cbd3\":{\"version\":\"3.3.2\",\"title\":\"Bokeh Application\",\"roots\":[{\"type\":\"object\",\"name\":\"panel.models.browser.BrowserInfo\",\"id\":\"p1004\"},{\"type\":\"object\",\"name\":\"panel.models.comm_manager.CommManager\",\"id\":\"p1005\",\"attributes\":{\"plot_id\":\"p1004\",\"comm_id\":\"a7492e8c49aa46d387bcc3a6ccd66757\",\"client_comm_id\":\"a02808c94b184d679bf218fb3916b118\"}}],\"defs\":[{\"type\":\"model\",\"name\":\"ReactiveHTML1\"},{\"type\":\"model\",\"name\":\"FlexBox1\",\"properties\":[{\"name\":\"align_content\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"align_items\",\"kind\":\"Any\",\"default\":\"flex-start\"},{\"name\":\"flex_direction\",\"kind\":\"Any\",\"default\":\"row\"},{\"name\":\"flex_wrap\",\"kind\":\"Any\",\"default\":\"wrap\"},{\"name\":\"justify_content\",\"kind\":\"Any\",\"default\":\"flex-start\"}]},{\"type\":\"model\",\"name\":\"FloatPanel1\",\"properties\":[{\"name\":\"config\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"contained\",\"kind\":\"Any\",\"default\":true},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"right-top\"},{\"name\":\"offsetx\",\"kind\":\"Any\",\"default\":null},{\"name\":\"offsety\",\"kind\":\"Any\",\"default\":null},{\"name\":\"theme\",\"kind\":\"Any\",\"default\":\"primary\"},{\"name\":\"status\",\"kind\":\"Any\",\"default\":\"normalized\"}]},{\"type\":\"model\",\"name\":\"GridStack1\",\"properties\":[{\"name\":\"mode\",\"kind\":\"Any\",\"default\":\"warn\"},{\"name\":\"ncols\",\"kind\":\"Any\",\"default\":null},{\"name\":\"nrows\",\"kind\":\"Any\",\"default\":null},{\"name\":\"allow_resize\",\"kind\":\"Any\",\"default\":true},{\"name\":\"allow_drag\",\"kind\":\"Any\",\"default\":true},{\"name\":\"state\",\"kind\":\"Any\",\"default\":[]}]},{\"type\":\"model\",\"name\":\"drag1\",\"properties\":[{\"name\":\"slider_width\",\"kind\":\"Any\",\"default\":5},{\"name\":\"slider_color\",\"kind\":\"Any\",\"default\":\"black\"},{\"name\":\"value\",\"kind\":\"Any\",\"default\":50}]},{\"type\":\"model\",\"name\":\"click1\",\"properties\":[{\"name\":\"terminal_output\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"debug_name\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"clears\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"toggle_value1\",\"properties\":[{\"name\":\"active_icons\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"options\",\"kind\":\"Any\",\"default\":{\"type\":\"map\",\"entries\":[[\"favorite\",\"heart\"]]}},{\"name\":\"value\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"_reactions\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"_base_url\",\"kind\":\"Any\",\"default\":\"https://tabler-icons.io/static/tabler-icons/icons/\"}]},{\"type\":\"model\",\"name\":\"copy_to_clipboard1\",\"properties\":[{\"name\":\"value\",\"kind\":\"Any\",\"default\":null},{\"name\":\"fill\",\"kind\":\"Any\",\"default\":\"none\"}]},{\"type\":\"model\",\"name\":\"FastWrapper1\",\"properties\":[{\"name\":\"object\",\"kind\":\"Any\",\"default\":null},{\"name\":\"style\",\"kind\":\"Any\",\"default\":null}]},{\"type\":\"model\",\"name\":\"NotificationAreaBase1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"NotificationArea1\",\"properties\":[{\"name\":\"js_events\",\"kind\":\"Any\",\"default\":{\"type\":\"map\"}},{\"name\":\"notifications\",\"kind\":\"Any\",\"default\":[]},{\"name\":\"position\",\"kind\":\"Any\",\"default\":\"bottom-right\"},{\"name\":\"_clear\",\"kind\":\"Any\",\"default\":0},{\"name\":\"types\",\"kind\":\"Any\",\"default\":[{\"type\":\"map\",\"entries\":[[\"type\",\"warning\"],[\"background\",\"#ffc107\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-exclamation-triangle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]},{\"type\":\"map\",\"entries\":[[\"type\",\"info\"],[\"background\",\"#007bff\"],[\"icon\",{\"type\":\"map\",\"entries\":[[\"className\",\"fas fa-info-circle\"],[\"tagName\",\"i\"],[\"color\",\"white\"]]}]]}]}]},{\"type\":\"model\",\"name\":\"Notification\",\"properties\":[{\"name\":\"background\",\"kind\":\"Any\",\"default\":null},{\"name\":\"duration\",\"kind\":\"Any\",\"default\":3000},{\"name\":\"icon\",\"kind\":\"Any\",\"default\":null},{\"name\":\"message\",\"kind\":\"Any\",\"default\":\"\"},{\"name\":\"notification_type\",\"kind\":\"Any\",\"default\":null},{\"name\":\"_destroyed\",\"kind\":\"Any\",\"default\":false}]},{\"type\":\"model\",\"name\":\"TemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"BootstrapTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]},{\"type\":\"model\",\"name\":\"MaterialTemplateActions1\",\"properties\":[{\"name\":\"open_modal\",\"kind\":\"Any\",\"default\":0},{\"name\":\"close_modal\",\"kind\":\"Any\",\"default\":0}]}]}};\n",
       "  var render_items = [{\"docid\":\"d712383a-8706-4e4e-91f6-c8407566cbd3\",\"roots\":{\"p1004\":\"e66d5396-573c-4ba6-ba4c-3336a87e21c8\"},\"root_ids\":[\"p1004\"]}];\n",
       "  var docs = Object.values(docs_json)\n",
       "  if (!docs) {\n",
       "    return\n",
       "  }\n",
       "  const py_version = docs[0].version.replace('rc', '-rc.').replace('.dev', '-dev.')\n",
       "  function embed_document(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "    for (const render_item of render_items) {\n",
       "      for (const root_id of render_item.root_ids) {\n",
       "\tconst id_el = document.getElementById(root_id)\n",
       "\tif (id_el.children.length && (id_el.children[0].className === 'bk-root')) {\n",
       "\t  const root_el = id_el.children[0]\n",
       "\t  root_el.id = root_el.id + '-rendered'\n",
       "\t}\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "  function get_bokeh(root) {\n",
       "    if (root.Bokeh === undefined) {\n",
       "      return null\n",
       "    } else if (root.Bokeh.version !== py_version) {\n",
       "      if (root.Bokeh.versions === undefined || !root.Bokeh.versions.has(py_version)) {\n",
       "\treturn null\n",
       "      }\n",
       "      return root.Bokeh.versions.get(py_version);\n",
       "    } else if (root.Bokeh.version === py_version) {\n",
       "      return root.Bokeh\n",
       "    }\n",
       "    return null\n",
       "  }\n",
       "  function is_loaded(root) {\n",
       "    var Bokeh = get_bokeh(root)\n",
       "    return (Bokeh != null && Bokeh.Panel !== undefined)\n",
       "  }\n",
       "  if (is_loaded(root)) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (is_loaded(root)) {\n",
       "        clearInterval(timer);\n",
       "        embed_document(root);\n",
       "      } else if (document.readyState == \"complete\") {\n",
       "        attempts++;\n",
       "        if (attempts > 200) {\n",
       "          clearInterval(timer);\n",
       "\t  var Bokeh = get_bokeh(root)\n",
       "\t  if (Bokeh == null || Bokeh.Panel == null) {\n",
       "            console.warn(\"Panel: ERROR: Unable to run Panel code because Bokeh or Panel library is missing\");\n",
       "\t  } else {\n",
       "\t    console.warn(\"Panel: WARNING: Attempting to render but not all required libraries could be resolved.\")\n",
       "\t    embed_document(root)\n",
       "\t  }\n",
       "        }\n",
       "      }\n",
       "    }, 25, root)\n",
       "  }\n",
       "})(window);</script>"
      ]
     },
     "metadata": {
      "application/vnd.holoviews_exec.v0+json": {
       "id": "p1004"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div class=\"logo-block\">\n",
       "<img src='data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAYAAACqaXHeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAAB+wAAAfsBxc2miwAAABl0RVh0U29mdHdhcmUAd3d3Lmlua3NjYXBlLm9yZ5vuPBoAAA6zSURB\n",
       "VHic7ZtpeFRVmsf/5966taWqUlUJ2UioBBJiIBAwCZtog9IOgjqACsogKtqirT2ttt069nQ/zDzt\n",
       "tI4+CrJIREFaFgWhBXpUNhHZQoKBkIUASchWla1S+3ar7r1nPkDaCAnZKoQP/D7mnPOe9/xy76n3\n",
       "nFSAW9ziFoPFNED2LLK5wcyBDObkb8ZkxuaoSYlI6ZcOKq1eWFdedqNzGHQBk9RMEwFAASkk0Xw3\n",
       "ETacDNi2vtvc7L0ROdw0AjoSotQVkKSvHQz/wRO1lScGModBFbDMaNRN1A4tUBCS3lk7BWhQkgpD\n",
       "lG4852/+7DWr1R3uHAZVQDsbh6ZPN7CyxUrCzJMRouusj0ipRwD2uKm0Zn5d2dFwzX1TCGhnmdGo\n",
       "G62Nna+isiUqhkzuKrkQaJlPEv5mFl2fvGg2t/VnzkEV8F5ioioOEWkLG86fvbpthynjdhXYZziQ\n",
       "x1hC9J2NFyi8vCTt91Fh04KGip0AaG9zuCk2wQCVyoNU3Hjezee9bq92duzzTmxsRJoy+jEZZZYo\n",
       "GTKJ6SJngdJqAfRzpze0+jHreUtPc7gpBLQnIYK6BYp/uGhw9YK688eu7v95ysgshcg9qSLMo3JC\n",
       "4jqLKQFBgdKDPoQ+Pltb8dUyQLpeDjeVgI6EgLIQFT5tEl3rn2losHVsexbZ3EyT9wE1uGdkIPcy\n",
       "BGxn8QUq1QrA5nqW5i2tLqvrrM9NK6AdkVIvL9E9bZL/oyfMVd/jqvc8LylzRBKDJSzIExwhQzuL\n",
       "QYGQj4rHfFTc8mUdu3E7yoLtbTe9gI4EqVgVkug2i5+uXGo919ixbRog+3fTbQ8qJe4ZOYNfMoTI\n",
       "OoshUNosgO60AisX15aeI2PSIp5KiFLI9ubb1vV3Qb2ltwLakUCDAkWX7/nHKRmmGIl9VgYsUhJm\n",
       "2NXjKYADtM1ygne9QQDIXlk49FBstMKx66D1v4+XuQr7vqTe0VcBHQlRWiOCbmmSYe2SqtL6q5rJ\n",
       "zsTb7lKx3FKOYC4DoqyS/B5bvLPxvD9Qtf6saxYLQGJErmDOdOMr/zo96km1nElr8bmPOBwI9COv\n",
       "HnFPRIwmkSOv9kcAS4heRsidOkpeWBgZM+UBrTFAXNYL5Vf2ii9c1trNzpYdaoVil3WIc+wdk+gQ\n",
       "noie3ecCcxt9ITcLAPWt/laGEO/9U6PmzZkenTtsSMQ8uYywJVW+grCstAvCIaAdArAsIWkRDDs/\n",
       "KzLm2YcjY1Lv0UdW73HabE9n6V66cxSzfEmuJssTpKGVp+0vHq73FwL46eOjpMpbRAnNmJFrGJNu\n",
       "Ukf9Yrz+3rghiumCKNXXWPhLYcjxGsIpoCMsIRoFITkW8AuyM8jC1+/QLx4bozCEJIq38+1rtpR6\n",
       "V/yzb8eBlRb3fo5l783N0CWolAzJHaVNzkrTzlEp2bQ2q3TC5gn6wpnoQAmwSiGh2GitnTmVMc5O\n",
       "UyfKWUKCIsU7+fZDKwqdT6DDpvkzAX4/+AMFjk0tDp5GRXLpQ2MUmhgDp5gxQT8+Y7hyPsMi8uxF\n",
       "71H0oebujHALECjFKaW9Lm68n18wXp2kVzIcABytD5iXFzg+WVXkegpAsOOYziqo0OkK76GyquC3\n",
       "ltZAzMhhqlSNmmWTE5T6e3IN05ITFLM4GdN0vtZ3ob8Jh1NAKXFbm5PtLU/eqTSlGjkNAJjdgn/N\n",
       "aedXa0tdi7+t9G0FIF49rtMSEgAs1kDLkTPO7ebm4IUWeyh1bKomXqlgMG6kJmHcSM0clYLJ8XtR\n",
       "1GTnbV3F6I5wCGikAb402npp1h1s7LQUZZSMIfALFOuL3UUrfnS8+rez7v9qcold5tilgHbO1fjK\n",
       "9ubb17u9oshxzMiUBKXWqJNxd+fqb0tLVs4lILFnK71H0Ind7uiPgACVcFJlrb0tV6DzxqqTIhUM\n",
       "CwDf1/rrVhTa33/3pGPxJYdQ2l2cbgVcQSosdx8uqnDtbGjh9SlDVSMNWhlnilfqZk42Th2ZpLpf\n",
       "xrHec5e815zrr0dfBZSwzkZfqsv+1FS1KUknUwPARVvItfKUY+cn57yP7qv07UE3p8B2uhUwLk09\n",
       "e0SCOrK+hbdYHYLjRIl71wWzv9jpEoeOHhGRrJAzyEyNiJuUqX0g2sBN5kGK6y2Blp5M3lsB9Qh4\n",
       "y2Ja6x6+i0ucmKgwMATwhSjdUu49tKrQ/pvN5d53ml2CGwCmJipmKjgmyuaXzNeL2a0AkQ01Th5j\n",
       "2DktO3Jyk8f9vcOBQHV94OK+fPumJmvQHxJoWkaKWq9Vs+yUsbq0zGT1I4RgeH2b5wef7+c7bl8F\n",
       "eKgoHVVZa8ZPEORzR6sT1BzDUAD/d9F78e2Tzv99v8D+fLVTqAKAsbGamKey1Mt9Ann4eH3gTXTz\n",
       "idWtAJ8PQWOk7NzSeQn/OTHDuEikVF1R4z8BQCy+6D1aWRfY0tTGG2OM8rRoPaeIj5ZHzJxszElN\n",
       "VM8K8JS5WOfv8mzRnQAKoEhmt8gyPM4lU9SmBK1MCQBnW4KONT86v1hZ1PbwSXPw4JWussVjtH9Y\n",
       "NCoiL9UoH/6PSu8jFrfY2t36erQHXLIEakMi1SydmzB31h3GGXFDFNPaK8Rme9B79Ixrd0WN+1ij\n",
       "NRQ/doRmuFLBkHSTOm5GruG+pFjFdAmorG4IXH1Qua6ASniclfFtDYt+oUjKipPrCQB7QBQ2lrgP\n",
       "fFzm+9XWUtcqJ3/5vDLDpJ79XHZk3u8nGZ42qlj1+ydtbxysCezrydp6ugmipNJ7WBPB5tydY0jP\n",
       "HaVNzs3QzeE4ZpTbI+ZbnSFPbVOw9vsfnVvqWnirPyCNGD08IlqtYkh2hjZ5dErEQzoNm+6ykyOt\n",
       "Lt5/PQEuSRRKo22VkydK+vvS1XEKlhCJAnsqvcVvH7f/ZU2R67eXbMEGAMiIV5oWZWiWvz5Fv2xG\n",
       "sjqNJQRvn3Rs2lji/lNP19VjAQDgD7FHhujZB9OGqYxRkZxixgRDVlqS6uEOFaJUVu0rPFzctrnF\n",
       "JqijImVp8dEKVWyUXDk92zAuMZ6bFwpBU1HrOw6AdhQgUooChb0+ItMbWJitSo5Ws3IAOGEOtL53\n",
       "0vHZih9sC4vtofZ7Qu6523V/fmGcds1TY3V36pUsBwAbSlxnVh2xLfAD/IAIMDf7XYIkNmXfpp2l\n",
       "18rkAJAy9HKFaIr/qULkeQQKy9zf1JgDB2uaeFNGijo5QsUyacNUUTOnGO42xSnv4oOwpDi1zYkc\n",
       "efUc3I5Gk6PhyTuVKaOGyLUAYPGIoY9Pu/atL/L92+4q9wbflRJ2Trpm/jPjdBtfnqB/dIThcl8A\n",
       "KG7hbRuKnb8qsQsVvVlTrwQAQMUlf3kwJI24Z4JhPMtcfng5GcH49GsrxJpGvvHIaeem2ma+KSjQ\n",
       "lIwUdYyCY8j4dE1KzijNnIP2llF2wcXNnsoapw9XxsgYAl6k+KzUXbi2yP3KR2ecf6z3BFsBICdW\n",
       "nvnIaG3eHybqX7vbpEqUMT+9OL4Qpe8VON7dXuFd39v19FoAABRVePbGGuXTszO0P7tu6lghUonE\n",
       "llRdrhArLvmKdh9u29jcFiRRkfLUxBiFNiqSU9icoZQHo5mYBI1MBgBH6wMNb+U7Pnw337H4gi1Y\n",
       "ciWs+uks3Z9fztUvfzxTm9Ne8XXkvQLHNytOOZeiD4e0PgkAIAYCYknKUNUDSXEKzdWNpnil7r4p\n",
       "xqkjTarZMtk/K8TQ6Qve78qqvXurGwIJqcOUKfUWHsm8KGvxSP68YudXq4pcj39X49uOK2X142O0\n",
       "Tz5/u/7TVybqH0rSya6ZBwD21/gubbrgWdDgEOx9WUhfBaC2ibcEBYm7a7x+ukrBMNcEZggyR0TE\n",
       "T8zUPjikQ4VosQZbTpS4vqizBKvqmvjsqnpfzaZyx9JPiz1/bfGKdgD45XB1zoIMzYbfTdS/NClB\n",
       "Gct0USiY3YL/g0LHy/uq/Ef6uo5+n0R/vyhp17Klpge763f8rMu6YU/zrn2nml+2WtH+Z+5IAAFc\n",
       "2bUTdTDOSNa9+cQY7YLsOIXhevEkCvzph7a8laecz/Un/z4/Ae04XeL3UQb57IwU9ZDr9UuKVajv\n",
       "nxp1+1UVIo/LjztZkKH59fO3G/JemqCfmaCRqbqbd90ZZ8FfjtkfAyD0J/9+C2h1hDwsSxvGjNDc\n",
       "b4zk5NfrSwiQblLHzZhg+Jf4aPlUwpDqkQqa9nimbt1/TDH8OitGMaQnj+RJS6B1fbF7SY1TqO5v\n",
       "/v0WAADl1f7zokgS7s7VT2DZ7pegUjBM7mjtiDZbcN4j0YrHH0rXpCtY0qPX0cVL0rv5jv/ZXend\n",
       "0u/EESYBAFBU4T4Qa5TflZOhTe7pmKpaP8kCVUVw1+yhXfJWvn1P3hnXi33JsTN6PnP3hHZ8Z3/h\n",
       "aLHzmkNPuPj7Bc/F/Q38CwjTpSwQXgE4Vmwry9tpfq/ZFgqFMy4AVDtCvi8rvMvOmv0N4YwbVgEA\n",
       "sPM72/KVnzfspmH7HQGCRLG2yL1+z8XwvPcdCbsAANh+xPzstgMtxeGKt+6MK3/tacfvwhWvIwMi\n",
       "oKEBtm0H7W+UVfkc/Y1V0BhoPlDr/w1w/eu1vjIgAgDg22OtX6/eYfnEz/focrZTHAFR+PSs56/7\n",
       "q32nwpjazxgwAQCwcU/T62t3WL7r6/jVRa6/byp1rei+Z98ZUAEAhEPHPc8fKnTU9nbgtnOe8h0l\n",
       "9hcGIqmODLQAHCy2Xti6v/XNRivf43f4fFvIteu854+VHnR7q9tfBlwAAGz+pnndB9vM26UebAe8\n",
       "SLHujPOTPVW+rwY+sxskAAC2HrA8t2Vvc7ffP1r9o+vwR2dcr92InIAbKKC1FZ5tB1tf+/G8p8sv\n",
       "N/9Q5zd/XR34LYCwV5JdccMEAMDBk45DH243r/X4xGvqxFa/GNpS7n6rwOwNWwHVE26oAADYurf1\n",
       "zx/utOzt+DMKYM0p17YtZZ5VNzqfsB2HewG1WXE8PoZ7gOclbTIvynZf9JV+fqZtfgs/8F/Nu5rB\n",
       "EIBmJ+8QRMmpU7EzGRsf2FzuePqYRbzh/zE26EwdrT10f6r6o8HOYzCJB9Dpff8tbnGLG8L/A/WE\n",
       "roTBs2RqAAAAAElFTkSuQmCC'\n",
       "     style='height:25px; border-radius:12px; display: inline-block; float: left; vertical-align: middle'></img>\n",
       "\n",
       "\n",
       "  <img src='data:image/png;base64,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'\n",
       "       style='height:15px; border-radius:12px; display: inline-block; float: left'></img>\n",
       "  \n",
       "\n",
       "\n",
       "\n",
       "\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import bokeh.plotting as bpl\n",
    "import cv2\n",
    "import glob\n",
    "import holoviews as hv\n",
    "from IPython import get_ipython\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import psutil\n",
    "\n",
    "import caiman as cm\n",
    "from caiman.source_extraction import cnmf\n",
    "from caiman.source_extraction.cnmf.cnmf import load_CNMF\n",
    "from caiman.utils.utils import download_demo\n",
    "from caiman.utils.visualization import inspect_correlation_pnr, nb_inspect_correlation_pnr\n",
    "from caiman.motion_correction import MotionCorrect\n",
    "from caiman.source_extraction.cnmf import params as params\n",
    "from caiman.utils.visualization import plot_contours, nb_view_patches, nb_plot_contour\n",
    "from caiman.utils.visualization import view_quilt\n",
    "\n",
    "try:\n",
    "    if __IPYTHON__:\n",
    "        get_ipython().run_line_magic('load_ext', 'autoreload')\n",
    "        get_ipython().run_line_magic('autoreload', '2')\n",
    "        # get_ipython().run_line_magic('matplotlib', 'qt')  #uncomment to run in qt mode\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    cv2.setNumThreads(0)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "bpl.output_notebook()\n",
    "hv.notebook_extension('bokeh')\n",
    "\n",
    "# Mesmerize inputs\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "import tifffile\n",
    "from ipywidgets import IntSlider, VBox\n",
    "import fastplotlib as fpl\n",
    "\n",
    "from caiman.motion_correction import high_pass_filter_space\n",
    "from caiman.summary_images import correlation_pnr\n",
    "\n",
    "import mesmerize_core as mc\n",
    "import caiman as cm\n",
    "from mesmerize_core.arrays import LazyTiff\n",
    "from mesmerize_viz import *\n",
    "from decode_lab_code.calcium_imaging import calcium_imaging_utils\n",
    "\n",
    "from mesmerize_core.caiman_extensions.cnmf import cnmf_cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up logger and environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up logging\n",
    "logging.basicConfig(format=\"{asctime} - {levelname} - [{filename} {funcName}() {lineno}] - pid {process} - {message}\",\n",
    "                    filename=None, \n",
    "                    level=logging.WARNING, style=\"{\") #logging level can be DEBUG, INFO, WARNING, ERROR, CRITICAL\n",
    "\n",
    "# set env variables in case they weren't already set\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"VECLIB_MAXIMUM_THREADS\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select file(s) to be processed\n",
    "Here, we analyze the data in `data_endoscope.tif`. The `download_demo` function will download the  file for you and return the complete path to the file which will be stored in your `caiman_data` directory. If you adapt this demo for your data make sure to pass the complete path to your file. \n",
    "\n",
    "Note that the memory requirement of the CNMF-E algorithm are much higher compared to the standard CNMF algorithm. You should test your system before trying to process very large amounts of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded batch\n"
     ]
    }
   ],
   "source": [
    "#movie_path = download_demo('data_endoscope.tif')  \n",
    "\n",
    "# directory stuff\n",
    "folder_name = \"/Users/js0403/miniscope/122A_session2_nwbfile\"\n",
    "file_name = \"movie.avi\"\n",
    "frame_rate = 30 # frames per sec\n",
    "mc.set_parent_raw_data_path(folder_name)\n",
    "\n",
    "# split frames and save data\n",
    "fname = [os.path.join(folder_name,file_name)]\n",
    "\n",
    "# get the actual file name\n",
    "movie_path  = mc.get_parent_raw_data_path().joinpath(file_name) # add to moviepath\n",
    "\n",
    "# batch stuff - don't worry about\n",
    "batch_path = mc.get_parent_raw_data_path().joinpath(\"mesmerize-batch/batch.pickle\")\n",
    "try:\n",
    "    # create a new batch\n",
    "    df = mc.create_batch(batch_path)\n",
    "    print(\"Created batch\")\n",
    "except:\n",
    "    # to load existing batches use `load_batch()`\n",
    "    df = mc.load_batch(batch_path)\n",
    "    print(\"Loaded batch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and visualize raw data\n",
    "We visualize using the built-in movie object, which is described in detail in `demo_pipeline.ipynb`. In addition to neural activity, you can also see blood flow in the movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-22 13:00:46,777 - WARNING - [movies.py load() 1476] - pid 3550 - deprecated pixel format used, make sure you did set range correctly\n",
      "2023-12-22 13:00:46,777 - WARNING - [movies.py load() 1476] - pid 3550 - No accelerated colorspace conversion found from yuv420p to bgr24.\n"
     ]
    }
   ],
   "source": [
    "# press q to close\n",
    "movie_orig = cm.load(str(movie_path)) \n",
    "downsampling_ratio = 0.2  # subsample 5x\n",
    "movie_orig.resize(fz=downsampling_ratio).play(gain=0.9,\n",
    "                                              q_max=99.5, \n",
    "                                              fr=frame_rate,\n",
    "                                              plot_text=True,\n",
    "                                              magnification=2,\n",
    "                                              do_loop=True,\n",
    "                                              backend='opencv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up a cluster\n",
    "To enable parallel computing we will set up a local cluster. The resulting variable `cluster` contains the pool of processors (CPUs) that will be used in later steps. If you use `dview=cluster` in later steps, then parallel processing will be used. If you use `dview=None` then no parallel processing will be used. The `num_processors_to_use` variable determines how many CPU dores you will use (when set to `None` it goes to the default of one less than the number available):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have 12 CPUs available in your current environment\n"
     ]
    }
   ],
   "source": [
    "print(f\"You have {psutil.cpu_count()} CPUs available in your current environment\")\n",
    "num_processors_to_use = 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up a cluster of processors. If one has already been set up (the multiprocessing_pool variable is already in your namespace), then that cluster will be closed and a new one created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up new cluster\n",
      "Successfully set up cluster with 11 processes\n"
     ]
    }
   ],
   "source": [
    "#%% start a cluster for parallel processing (if a cluster already exists it will be closed and a new session will be opened)\n",
    "if 'cluster' in locals():  # 'locals' contains list of current local variables\n",
    "    print('Closing previous cluster')\n",
    "    cm.stop_server(dview=cluster)\n",
    "print(\"Setting up new cluster\")\n",
    "_, cluster, n_processes = cm.cluster.setup_cluster(backend='multiprocessing', \n",
    "                                                 n_processes=num_processors_to_use, \n",
    "                                                 ignore_preexisting=False)\n",
    "print(f\"Successfully set up cluster with {n_processes} processes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize data to define parameter space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stride = 100; overlap = 50; width = stride+overlap; rf = int(width/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'movie_orig' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m stride \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m; overlap \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m; width \u001b[38;5;241m=\u001b[39m stride\u001b[38;5;241m+\u001b[39moverlap; rf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(width\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m calcium_imaging_utils\u001b[38;5;241m.\u001b[39mview_quilt(template_image\u001b[38;5;241m=\u001b[39m\u001b[43mmovie_orig\u001b[49m[\u001b[38;5;241m0\u001b[39m,:,:],stride\u001b[38;5;241m=\u001b[39mstride,overlap\u001b[38;5;241m=\u001b[39moverlap)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'movie_orig' is not defined"
     ]
    }
   ],
   "source": [
    "calcium_imaging_utils.view_quilt(template_image=movie_orig[0,:,:],stride=stride,overlap=overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52d414ad390d476aa539ad24621599eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RFBOutputContext()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/js0403/anaconda3/envs/caiman/lib/python3.11/site-packages/fastplotlib/graphics/_features/_base.py:34: UserWarning: converting float64 array to float32\n",
      "  warn(f\"converting {array.dtype} array to float32\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f5070f195a04682bae05ce40cb6ea7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(JupyterOutputContext(children=(JupyterWgpuCanvas(css_height='600px', css_width='1200px'), Ipywi"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a slider for gSig_filt\n",
    "slider_gsig_filt = IntSlider(value=3, min=1, max=33, step=2,  description=\"gSig_filt\")\n",
    "\n",
    "def apply_filter(frame):\n",
    "    # read slider value\n",
    "    gSig_filt = (slider_gsig_filt.value, slider_gsig_filt.value)\n",
    "    \n",
    "    # apply filter\n",
    "    return high_pass_filter_space(frame, gSig_filt)\n",
    "\n",
    "# we can use frame_apply feature of `ImageWidget` to apply \n",
    "# the filter before displaying frames\n",
    "funcs = {\n",
    "    # data_index: function\n",
    "    1: apply_filter  # filter shown on right plot, index 1\n",
    "}\n",
    "\n",
    "# input movie will be shown on left, filtered on right\n",
    "iw_gs = fpl.ImageWidget(\n",
    "    data=[movie_orig, movie_orig.copy()],\n",
    "    frame_apply=funcs,\n",
    "    names=[\"raw\", \"filtered\"],\n",
    "    grid_plot_kwargs={\"size\": (1200, 600)},\n",
    "    cmap=\"gnuplot2\"\n",
    ")\n",
    "\n",
    "def force_update(*args):\n",
    "    # kinda hacky but forces the images to update \n",
    "    # when the gSig_filt slider is moved\n",
    "    iw_gs.current_index = iw_gs.current_index\n",
    "    iw_gs.reset_vmin_vmax()\n",
    "\n",
    "iw_gs.reset_vmin_vmax()\n",
    "slider_gsig_filt.observe(force_update, \"value\")\n",
    "VBox([iw_gs.show(), slider_gsig_filt])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up some parameters\n",
    "We first set some parameters related to the data and motion correction and create a `params` object. We'll modify this parameter object later on with settings for source extraction. You can also set all the parameters at once as demonstrated in the `demo_pipeline.ipynb` notebook.\n",
    "\n",
    "Note here we are setting `pw_rigid` to `False` as our data seems to mainly contain large-scale translational motion. We can always redo this later if it turns out to be a mistake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gSig_val = 9 # update based on results from above\n",
    "\n",
    "# dataset dependent parameters\n",
    "frate = frame_rate                     # movie frame rate\n",
    "decay_time = 0.4                 # length of a typical transient in seconds\n",
    "\n",
    "# motion correction parameters\n",
    "motion_correct = True    # flag for performing motion correction\n",
    "pw_rigid = False         # flag for performing piecewise-rigid motion correction (otherwise just rigid)\n",
    "gSig_filt = (gSig_val, gSig_val)       # size of high pass spatial filtering, used in 1p data\n",
    "max_shifts = (5, 5)      # maximum allowed rigid shift\n",
    "strides = (stride, stride)       # start a new patch for pw-rigid motion correction every x pixels\n",
    "overlaps = (overlap, overlap)      # overlap between pathes (size of patch strides+overlaps)\n",
    "max_deviation_rigid = 3  # maximum deviation allowed for patch with respect to rigid shifts\n",
    "border_nan = 'copy'      # replicate values along the boundaries\n",
    "\n",
    "mc_dict = {\n",
    "    'fnames': str(movie_path),\n",
    "    'fr': frate,\n",
    "    'decay_time': decay_time,\n",
    "    'pw_rigid': pw_rigid,\n",
    "    'max_shifts': max_shifts,\n",
    "    'gSig_filt': gSig_filt,\n",
    "    'strides': strides,\n",
    "    'overlaps': overlaps,\n",
    "    'max_deviation_rigid': max_deviation_rigid,\n",
    "    'border_nan': border_nan\n",
    "}\n",
    "\n",
    "parameters = params.CNMFParams(params_dict=mc_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motion Correction\n",
    "The background signal in micro-endoscopic data is very strong and makes motion correction challenging. As a first step the algorithm performs a high pass spatial filtering with a Gaussian kernel to remove the bulk of the lower-frequency background activity and enhance spatial landmarks. The size of the kernel is given from the parameter `gSig_filt`. If this is left to the default value of `None` then no spatial filtering is performed (default option, used in 2p data for CNMF). \n",
    "\n",
    "After spatial filtering, the NoRMCorre algorithm is used to determine the motion in each frame. The inferred motion is then applied to the *original* data, so no information is lost before source separation. The motion corrected files are saved in memory mapped format. If no motion correction is performed (i.e., `motion_correct` was set to `False`), then the file gets directly memory mapped.\n",
    "\n",
    "> For a more detailed exploration of Caiman's motion correction pipeline, see `demo_motion_correction.ipynb`. \n",
    "\n",
    "The following also plots the discovered displacements in x- and y- in the movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-22 13:05:33,142 - WARNING - [movies.py load() 1476] - pid 3550 - deprecated pixel format used, make sure you did set range correctly\n",
      "2023-12-22 13:05:33,143 - WARNING - [movies.py load() 1476] - pid 3550 - No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "2023-12-22 13:05:35,939 - WARNING - [movies.py load() 1476] - pid 3550 - deprecated pixel format used, make sure you did set range correctly\n",
      "2023-12-22 13:05:35,939 - WARNING - [movies.py load() 1476] - pid 3550 - No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "2023-12-22 13:05:36,897 - WARNING - [movies.py extract_shifts() 341] - pid 3550 - Movie average is negative. Removing 1st percentile.\n",
      "2023-12-22 13:05:37,566 - WARNING - [movies.py extract_shifts() 341] - pid 3550 - Movie average is negative. Removing 1st percentile.\n",
      "2023-12-22 13:05:38,208 - WARNING - [movies.py extract_shifts() 341] - pid 3550 - Movie average is negative. Removing 1st percentile.\n",
      "deprecated pixel format used, make sure you did set range correctly\n",
      "No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "deprecated pixel format used, make sure you did set range correctly\n",
      "No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "deprecated pixel format used, make sure you did set range correctly\n",
      "No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "deprecated pixel format used, make sure you did set range correctly\n",
      "No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "deprecated pixel format used, make sure you did set range correctly\n",
      "No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "deprecated pixel format used, make sure you did set range correctly\n",
      "No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "deprecated pixel format used, make sure you did set range correctly\n",
      "No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "deprecated pixel format used, make sure you did set range correctly\n",
      "No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "deprecated pixel format used, make sure you did set range correctly\n",
      "No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "deprecated pixel format used, make sure you did set range correctly\n",
      "No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "deprecated pixel format used, make sure you did set range correctly\n",
      "No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "WARNING:libav.swscaler:deprecated pixel format used, make sure you did set range correctly\n",
      "WARNING:libav.swscaler:No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "WARNING:libav.swscaler:deprecated pixel format used, make sure you did set range correctly\n",
      "WARNING:libav.swscaler:No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "WARNING:libav.swscaler:deprecated pixel format used, make sure you did set range correctly\n",
      "WARNING:libav.swscaler:No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "WARNING:libav.swscaler:deprecated pixel format used, make sure you did set range correctly\n",
      "WARNING:libav.swscaler:deprecated pixel format used, make sure you did set range correctly\n",
      "WARNING:libav.swscaler:No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "WARNING:libav.swscaler:No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "WARNING:libav.swscaler:deprecated pixel format used, make sure you did set range correctly\n",
      "WARNING:libav.swscaler:No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "WARNING:libav.swscaler:deprecated pixel format used, make sure you did set range correctly\n",
      "WARNING:libav.swscaler:No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "WARNING:libav.swscaler:deprecated pixel format used, make sure you did set range correctly\n",
      "WARNING:libav.swscaler:No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "WARNING:libav.swscaler:deprecated pixel format used, make sure you did set range correctly\n",
      "WARNING:libav.swscaler:No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "WARNING:libav.swscaler:deprecated pixel format used, make sure you did set range correctly\n",
      "WARNING:libav.swscaler:No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "WARNING:libav.swscaler:deprecated pixel format used, make sure you did set range correctly\n",
      "WARNING:libav.swscaler:No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "WARNING:libav.swscaler:deprecated pixel format used, make sure you did set range correctly\n",
      "WARNING:libav.swscaler:No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "WARNING:libav.swscaler:deprecated pixel format used, make sure you did set range correctly\n",
      "WARNING:libav.swscaler:No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "WARNING:libav.swscaler:deprecated pixel format used, make sure you did set range correctly\n",
      "WARNING:libav.swscaler:No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "WARNING:libav.swscaler:deprecated pixel format used, make sure you did set range correctly\n",
      "WARNING:libav.swscaler:No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "WARNING:libav.swscaler:deprecated pixel format used, make sure you did set range correctly\n",
      "WARNING:libav.swscaler:No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "WARNING:libav.swscaler:deprecated pixel format used, make sure you did set range correctly\n",
      "WARNING:libav.swscaler:No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "WARNING:libav.swscaler:deprecated pixel format used, make sure you did set range correctly\n",
      "WARNING:libav.swscaler:No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "WARNING:libav.swscaler:deprecated pixel format used, make sure you did set range correctly\n",
      "WARNING:libav.swscaler:No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "WARNING:libav.swscaler:deprecated pixel format used, make sure you did set range correctly\n",
      "WARNING:libav.swscaler:No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "WARNING:libav.swscaler:deprecated pixel format used, make sure you did set range correctly\n",
      "WARNING:libav.swscaler:No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "WARNING:libav.swscaler:deprecated pixel format used, make sure you did set range correctly\n",
      "WARNING:libav.swscaler:No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "WARNING:libav.swscaler:deprecated pixel format used, make sure you did set range correctly\n",
      "WARNING:libav.swscaler:No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "WARNING:libav.swscaler:deprecated pixel format used, make sure you did set range correctly\n",
      "WARNING:libav.swscaler:No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "WARNING:libav.swscaler:deprecated pixel format used, make sure you did set range correctly\n",
      "WARNING:libav.swscaler:No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "WARNING:libav.swscaler:deprecated pixel format used, make sure you did set range correctly\n",
      "WARNING:libav.swscaler:No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "WARNING:libav.swscaler:deprecated pixel format used, make sure you did set range correctly\n",
      "WARNING:libav.swscaler:No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "WARNING:libav.swscaler:deprecated pixel format used, make sure you did set range correctly\n",
      "WARNING:libav.swscaler:No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "WARNING:libav.swscaler:deprecated pixel format used, make sure you did set range correctly\n",
      "WARNING:libav.swscaler:No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "WARNING:libav.swscaler:deprecated pixel format used, make sure you did set range correctly\n",
      "WARNING:libav.swscaler:No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "WARNING:libav.swscaler:deprecated pixel format used, make sure you did set range correctly\n",
      "WARNING:libav.swscaler:No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "WARNING:libav.swscaler:deprecated pixel format used, make sure you did set range correctly\n",
      "WARNING:libav.swscaler:No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "WARNING:libav.swscaler:deprecated pixel format used, make sure you did set range correctly\n",
      "WARNING:libav.swscaler:No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "WARNING:libav.swscaler:deprecated pixel format used, make sure you did set range correctly\n",
      "WARNING:libav.swscaler:No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "WARNING:libav.swscaler:deprecated pixel format used, make sure you did set range correctly\n",
      "WARNING:libav.swscaler:No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "WARNING:libav.swscaler:deprecated pixel format used, make sure you did set range correctly\n",
      "WARNING:libav.swscaler:No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "WARNING:libav.swscaler:deprecated pixel format used, make sure you did set range correctly\n",
      "WARNING:libav.swscaler:No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "WARNING:libav.swscaler:deprecated pixel format used, make sure you did set range correctly\n",
      "WARNING:libav.swscaler:No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "WARNING:libav.swscaler:deprecated pixel format used, make sure you did set range correctly\n",
      "WARNING:libav.swscaler:No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "WARNING:libav.swscaler:deprecated pixel format used, make sure you did set range correctly\n",
      "WARNING:libav.swscaler:No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "WARNING:libav.swscaler:deprecated pixel format used, make sure you did set range correctly\n",
      "WARNING:libav.swscaler:No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "WARNING:libav.swscaler:deprecated pixel format used, make sure you did set range correctly\n",
      "WARNING:libav.swscaler:No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "WARNING:libav.swscaler:deprecated pixel format used, make sure you did set range correctly\n",
      "WARNING:libav.swscaler:No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "WARNING:libav.swscaler:deprecated pixel format used, make sure you did set range correctly\n",
      "WARNING:libav.swscaler:No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "WARNING:libav.swscaler:deprecated pixel format used, make sure you did set range correctly\n",
      "WARNING:libav.swscaler:No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "WARNING:libav.swscaler:deprecated pixel format used, make sure you did set range correctly\n",
      "WARNING:libav.swscaler:No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "WARNING:libav.swscaler:deprecated pixel format used, make sure you did set range correctly\n",
      "WARNING:libav.swscaler:No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "WARNING:libav.swscaler:deprecated pixel format used, make sure you did set range correctly\n",
      "WARNING:libav.swscaler:No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "WARNING:libav.swscaler:deprecated pixel format used, make sure you did set range correctly\n",
      "WARNING:libav.swscaler:No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "WARNING:libav.swscaler:deprecated pixel format used, make sure you did set range correctly\n",
      "WARNING:libav.swscaler:No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "WARNING:libav.swscaler:deprecated pixel format used, make sure you did set range correctly\n",
      "WARNING:libav.swscaler:No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "WARNING:libav.swscaler:deprecated pixel format used, make sure you did set range correctly\n",
      "WARNING:libav.swscaler:No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "WARNING:libav.swscaler:deprecated pixel format used, make sure you did set range correctly\n",
      "WARNING:libav.swscaler:No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "WARNING:libav.swscaler:deprecated pixel format used, make sure you did set range correctly\n",
      "WARNING:libav.swscaler:No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "WARNING:libav.swscaler:deprecated pixel format used, make sure you did set range correctly\n",
      "WARNING:libav.swscaler:No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "WARNING:libav.swscaler:deprecated pixel format used, make sure you did set range correctly\n",
      "WARNING:libav.swscaler:No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "WARNING:libav.swscaler:deprecated pixel format used, make sure you did set range correctly\n",
      "WARNING:libav.swscaler:No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "WARNING:libav.swscaler:deprecated pixel format used, make sure you did set range correctly\n",
      "WARNING:libav.swscaler:No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "WARNING:libav.swscaler:deprecated pixel format used, make sure you did set range correctly\n",
      "WARNING:libav.swscaler:No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "WARNING:libav.swscaler:deprecated pixel format used, make sure you did set range correctly\n",
      "WARNING:libav.swscaler:No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "WARNING:libav.swscaler:deprecated pixel format used, make sure you did set range correctly\n",
      "WARNING:libav.swscaler:No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "WARNING:libav.swscaler:deprecated pixel format used, make sure you did set range correctly\n",
      "WARNING:libav.swscaler:No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "WARNING:libav.swscaler:deprecated pixel format used, make sure you did set range correctly\n",
      "WARNING:libav.swscaler:No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "WARNING:libav.swscaler:deprecated pixel format used, make sure you did set range correctly\n",
      "WARNING:libav.swscaler:No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "WARNING:libav.swscaler:deprecated pixel format used, make sure you did set range correctly\n",
      "WARNING:libav.swscaler:No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "WARNING:libav.swscaler:deprecated pixel format used, make sure you did set range correctly\n",
      "WARNING:libav.swscaler:No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "WARNING:libav.swscaler:deprecated pixel format used, make sure you did set range correctly\n",
      "WARNING:libav.swscaler:No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "WARNING:libav.swscaler:deprecated pixel format used, make sure you did set range correctly\n",
      "WARNING:libav.swscaler:No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "WARNING:libav.swscaler:deprecated pixel format used, make sure you did set range correctly\n",
      "WARNING:libav.swscaler:No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "WARNING:libav.swscaler:deprecated pixel format used, make sure you did set range correctly\n",
      "WARNING:libav.swscaler:No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "WARNING:libav.swscaler:deprecated pixel format used, make sure you did set range correctly\n",
      "WARNING:libav.swscaler:No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "WARNING:libav.swscaler:deprecated pixel format used, make sure you did set range correctly\n",
      "WARNING:libav.swscaler:No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "WARNING:libav.swscaler:deprecated pixel format used, make sure you did set range correctly\n",
      "WARNING:libav.swscaler:No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "WARNING:libav.swscaler:deprecated pixel format used, make sure you did set range correctly\n",
      "WARNING:libav.swscaler:No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "WARNING:libav.swscaler:deprecated pixel format used, make sure you did set range correctly\n",
      "WARNING:libav.swscaler:No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "WARNING:libav.swscaler:deprecated pixel format used, make sure you did set range correctly\n",
      "WARNING:libav.swscaler:No accelerated colorspace conversion found from yuv420p to bgr24.\n",
      "WARNING:libav.swscaler:deprecated pixel format used, make sure you did set range correctly\n",
      "WARNING:libav.swscaler:No accelerated colorspace conversion found from yuv420p to bgr24.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.4 s, sys: 35.5 s, total: 49.8 s\n",
      "Wall time: 4min 57s\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "if motion_correct:\n",
    "    # do motion correction rigid\n",
    "    mot_correct = MotionCorrect(str(movie_path), dview=cluster, **parameters.get_group('motion'))\n",
    "    mot_correct.motion_correct(save_movie=True)\n",
    "    fname_mc = mot_correct.fname_tot_els if pw_rigid else mot_correct.fname_tot_rig\n",
    "    if pw_rigid:\n",
    "        bord_px = np.ceil(np.maximum(np.max(np.abs(mot_correct.x_shifts_els)),\n",
    "                                     np.max(np.abs(mot_correct.y_shifts_els)))).astype(int)\n",
    "    else:\n",
    "        bord_px = np.ceil(np.max(np.abs(mot_correct.shifts_rig))).astype(int)\n",
    "        # Plot shifts\n",
    "        plt.plot(mot_correct.shifts_rig)  # % plot rigid shifts\n",
    "        plt.legend(['x shifts', 'y shifts'])\n",
    "        plt.xlabel('frames')\n",
    "        plt.ylabel('pixels')\n",
    "        plt.gcf().set_size_inches(6,3)\n",
    "        plt.axhline(y=max_deviation_rigid, color='r', linestyle='-')\n",
    "        plt.axhline(y=-1*max_deviation_rigid, color='r', linestyle='-')\n",
    "        plt.title(\"Make sure that your max shifts dont exceed or peak at the red lines\")\n",
    "        \n",
    "\n",
    "    bord_px = 0 if border_nan == 'copy' else bord_px\n",
    "    fname_new = cm.save_memmap(fname_mc, base_name='memmap_', order='C',\n",
    "                               border_to_0=bord_px)\n",
    "else:  # if no motion correction just memory map the file\n",
    "    fname_new = cm.save_memmap(movie_path, base_name='memmap_',\n",
    "                               order='C', border_to_0=0, dview=dview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare original (left) and motion corrected movie (right).\n",
    "\n",
    "You will probably notice they look pretty similar, as there wasn't much motion to begin with. You can see from the shift plot (plotted above) that the extracted shifts were all very small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1/1 [01:01<00:00, 61.54s/it]\n"
     ]
    }
   ],
   "source": [
    "movie_corrected = cm.load(mot_correct.mmap_file) # load motion corrected movie\n",
    "ds_ratio = 0.2\n",
    "cm.concatenate([movie_orig.resize(1, 1, ds_ratio) - mot_correct.min_mov*mot_correct.nonneg_movie,\n",
    "                movie_corrected.resize(1, 1, ds_ratio)], \n",
    "                axis=2).play(fr=30, \n",
    "                             gain=0.9, \n",
    "                             magnification=2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load memory mapped file\n",
    "Memory mapping is discussed in some detail in `demo_pipeline.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7082, 600, 600)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load memory mappable file\n",
    "fname_new = '/Users/js0403/miniscope/122A_session2_nwbfile/memmap_d1_600_d2_600_d3_1_order_C_frames_7082.mmap'\n",
    "Yr, dims, T = cm.load_memmap(fname_new)\n",
    "images = Yr.T.reshape((T,) + dims, order='F')\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNMFE requires a good pnr and corr input, so lets visualize to define them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gSig = gSig_val\n",
    "corr, pnr = correlation_pnr(images[::2], gSig=gSig, swap_dim=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to show the correlation and pnr images\n",
    "iw_corr_pnr = fpl.ImageWidget(\n",
    "    [corr, pnr], \n",
    "    names=[\"corr\", \"pnr\"],\n",
    "    grid_plot_kwargs={\"size\": (650, 300)},\n",
    "    cmap=\"turbo\",\n",
    ")\n",
    "\n",
    "# mcorr vids, we will display thresholded mcorr vids\n",
    "mcorr_vids = [images.astype(np.float32) for i in range(4)]\n",
    "\n",
    "# sync the threshold image widget with the corr-pnr plot\n",
    "threshold_grid_plot_kwargs = {\n",
    "    \"controllers\": [[iw_corr_pnr.gridplot[\"corr\"].controller]*2]*2,\n",
    "    \"size\": (650, 600)\n",
    "}\n",
    "\n",
    "iw_thres_movie = fpl.ImageWidget(\n",
    "    mcorr_vids, \n",
    "    names=[\"over corr threshold\", \"over pnr threshold\", \"under corr threshold\", \"under pnr threshold\"],\n",
    "    # sync this with the corr-pnr plot\n",
    "    grid_plot_kwargs=threshold_grid_plot_kwargs,\n",
    "    cmap=\"gnuplot2\"\n",
    ")\n",
    "\n",
    "# display threshold of the spatially filtered movie\n",
    "def spatial_filter(frame):\n",
    "    f = high_pass_filter_space(frame, (3, 3))\n",
    "    return f\n",
    "\n",
    "\n",
    "# threshold\n",
    "def threshold(frame, mask):\n",
    "    # optionally use spatial filter\n",
    "    t = spatial_filter(frame)\n",
    "    \n",
    "    t = t.copy()\n",
    "    \n",
    "    t[mask] = t.min()\n",
    "    \n",
    "    return t\n",
    "\n",
    "# Set the thresholded images using the vmin set from top subplots\n",
    "# dict of threshold lambda wrappers to set on ImageWidget\n",
    "# this sets the frame_apply for each subplot\n",
    "threshold_funcs = {\n",
    "    0: lambda frame: threshold(frame, corr < iw_corr_pnr.gridplot[\"corr\"].graphics[0].cmap.vmin),\n",
    "    1: lambda frame: threshold(frame, pnr < iw_corr_pnr.gridplot[\"pnr\"].graphics[0].cmap.vmin),\n",
    "    2: lambda frame: threshold(frame, corr > iw_corr_pnr.gridplot[\"corr\"].graphics[0].cmap.vmin),\n",
    "    3: lambda frame: threshold(frame, pnr > iw_corr_pnr.gridplot[\"pnr\"].graphics[0].cmap.vmin)\n",
    "}\n",
    "\n",
    "# set the dict of lambda wrappers\n",
    "iw_thres_movie.frame_apply = threshold_funcs\n",
    "\n",
    "# update threshold plots when the corr pnr sliders move\n",
    "def update_threshold_plots(*args):\n",
    "    iw_thres_movie.current_index = iw_thres_movie.current_index\n",
    "\n",
    "# this will get easier in the future\n",
    "iw_corr_pnr.gridplot[\"corr\"].docks[\"right\"][\"histogram_lut\"].linear_region.selection.add_event_handler(update_threshold_plots)\n",
    "iw_corr_pnr.gridplot[\"pnr\"].docks[\"right\"][\"histogram_lut\"].linear_region.selection.add_event_handler(update_threshold_plots)\n",
    "\n",
    "#VBox([iw_corr_pnr.show(), iw_thres_movie.show()])\n",
    "VBox([iw_corr_pnr.show()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic assignment of min_corr and min_pnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min_corr': 0.49309247732162476, 'min_pnr': 2.5695302486419678}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_pnr_inputs = {\n",
    "    'min_corr': iw_corr_pnr.gridplot[\"corr\"].graphics[0].cmap.vmin, # corr value from previous plot\n",
    "    'min_pnr': iw_corr_pnr.gridplot[\"pnr\"].graphics[0].cmap.vmin,  # PNR value from previous plot\n",
    "}\n",
    "corr_pnr_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49309247732162476"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_pnr_inputs['min_corr']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter setting for CNMF-E\n",
    "Everything is now set up to run source extraction with CNMFE. We will construct a new parameter dictionary and use this to modify the *existing* `parameters` object, using the `change_params()` method.\n",
    "\n",
    "There are *two* main differences between the CNMF and CNMFE source separation algorithms. The first is the background model (this is discussed in the sidebar below on the Ring Model). The second difference is in how the models are initialized. This is addressed below when we go over setting corr/pnr thresholds for initialization, which we did not have to do for our 2p data.\n",
    "\n",
    "We will explain the important differences in more detail below. For now, note that we have set `gnb` to `0`: this is effectively the flag telling Caiman to use CNMFE instead of CNMF. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gSig_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Catching an error on gSig - fix\n",
    "bord_pix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/js0403/decode_lab_code/scripts_and_notebooks/projects/miniscope/134A_CNMFE_MESMERIZE.ipynb Cell 33\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/js0403/decode_lab_code/scripts_and_notebooks/projects/miniscope/134A_CNMFE_MESMERIZE.ipynb#X31sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m ssub_B \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m          \u001b[39m# additional downsampling factor in space for background (increase to 2 if slow)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/js0403/decode_lab_code/scripts_and_notebooks/projects/miniscope/134A_CNMFE_MESMERIZE.ipynb#X31sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m ring_size_factor \u001b[39m=\u001b[39m \u001b[39m1.4\u001b[39m  \u001b[39m# radius of ring is gSiz*ring_size_factor\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/js0403/decode_lab_code/scripts_and_notebooks/projects/miniscope/134A_CNMFE_MESMERIZE.ipynb#X31sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m parameters\u001b[39m.\u001b[39;49mchange_params(params_dict\u001b[39m=\u001b[39;49m{\u001b[39m'\u001b[39;49m\u001b[39mmethod_init\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m'\u001b[39;49m\u001b[39mcorr_pnr\u001b[39;49m\u001b[39m'\u001b[39;49m,  \u001b[39m# use this for 1 photon\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/js0403/decode_lab_code/scripts_and_notebooks/projects/miniscope/134A_CNMFE_MESMERIZE.ipynb#X31sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m                                 \u001b[39m'\u001b[39;49m\u001b[39mK\u001b[39;49m\u001b[39m'\u001b[39;49m: K,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/js0403/decode_lab_code/scripts_and_notebooks/projects/miniscope/134A_CNMFE_MESMERIZE.ipynb#X31sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m                                 \u001b[39m'\u001b[39;49m\u001b[39mgSig\u001b[39;49m\u001b[39m'\u001b[39;49m: gSig,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/js0403/decode_lab_code/scripts_and_notebooks/projects/miniscope/134A_CNMFE_MESMERIZE.ipynb#X31sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m                                 \u001b[39m'\u001b[39;49m\u001b[39mgSiz\u001b[39;49m\u001b[39m'\u001b[39;49m: gSiz,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/js0403/decode_lab_code/scripts_and_notebooks/projects/miniscope/134A_CNMFE_MESMERIZE.ipynb#X31sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m                                 \u001b[39m'\u001b[39;49m\u001b[39mmerge_thr\u001b[39;49m\u001b[39m'\u001b[39;49m: merge_thr,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/js0403/decode_lab_code/scripts_and_notebooks/projects/miniscope/134A_CNMFE_MESMERIZE.ipynb#X31sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m                                 \u001b[39m'\u001b[39;49m\u001b[39mp\u001b[39;49m\u001b[39m'\u001b[39;49m: p,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/js0403/decode_lab_code/scripts_and_notebooks/projects/miniscope/134A_CNMFE_MESMERIZE.ipynb#X31sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m                                 \u001b[39m'\u001b[39;49m\u001b[39mtsub\u001b[39;49m\u001b[39m'\u001b[39;49m: tsub,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/js0403/decode_lab_code/scripts_and_notebooks/projects/miniscope/134A_CNMFE_MESMERIZE.ipynb#X31sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m                                 \u001b[39m'\u001b[39;49m\u001b[39mssub\u001b[39;49m\u001b[39m'\u001b[39;49m: ssub,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/js0403/decode_lab_code/scripts_and_notebooks/projects/miniscope/134A_CNMFE_MESMERIZE.ipynb#X31sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m                                 \u001b[39m'\u001b[39;49m\u001b[39mrf\u001b[39;49m\u001b[39m'\u001b[39;49m: rf,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/js0403/decode_lab_code/scripts_and_notebooks/projects/miniscope/134A_CNMFE_MESMERIZE.ipynb#X31sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m                                 \u001b[39m'\u001b[39;49m\u001b[39mstride\u001b[39;49m\u001b[39m'\u001b[39;49m: stride_cnmf,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/js0403/decode_lab_code/scripts_and_notebooks/projects/miniscope/134A_CNMFE_MESMERIZE.ipynb#X31sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m                                 \u001b[39m'\u001b[39;49m\u001b[39monly_init\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39mTrue\u001b[39;49;00m,    \u001b[39m# set it to True to run CNMF-E\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/js0403/decode_lab_code/scripts_and_notebooks/projects/miniscope/134A_CNMFE_MESMERIZE.ipynb#X31sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m                                 \u001b[39m'\u001b[39;49m\u001b[39mnb\u001b[39;49m\u001b[39m'\u001b[39;49m: gnb,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/js0403/decode_lab_code/scripts_and_notebooks/projects/miniscope/134A_CNMFE_MESMERIZE.ipynb#X31sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m                                 \u001b[39m'\u001b[39;49m\u001b[39mnb_patch\u001b[39;49m\u001b[39m'\u001b[39;49m: nb_patch,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/js0403/decode_lab_code/scripts_and_notebooks/projects/miniscope/134A_CNMFE_MESMERIZE.ipynb#X31sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m                                 \u001b[39m'\u001b[39;49m\u001b[39mmethod_deconvolution\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m'\u001b[39;49m\u001b[39moasis\u001b[39;49m\u001b[39m'\u001b[39;49m,       \u001b[39m# could use 'cvxpy' alternatively\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/js0403/decode_lab_code/scripts_and_notebooks/projects/miniscope/134A_CNMFE_MESMERIZE.ipynb#X31sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m                                 \u001b[39m'\u001b[39;49m\u001b[39mlow_rank_background\u001b[39;49m\u001b[39m'\u001b[39;49m: low_rank_background,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/js0403/decode_lab_code/scripts_and_notebooks/projects/miniscope/134A_CNMFE_MESMERIZE.ipynb#X31sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m                                 \u001b[39m'\u001b[39;49m\u001b[39mupdate_background_components\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39mTrue\u001b[39;49;00m,  \u001b[39m# sometimes setting to False improve the results\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/js0403/decode_lab_code/scripts_and_notebooks/projects/miniscope/134A_CNMFE_MESMERIZE.ipynb#X31sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m                                 \u001b[39m'\u001b[39;49m\u001b[39mmin_corr\u001b[39;49m\u001b[39m'\u001b[39;49m: min_corr,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/js0403/decode_lab_code/scripts_and_notebooks/projects/miniscope/134A_CNMFE_MESMERIZE.ipynb#X31sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m                                 \u001b[39m'\u001b[39;49m\u001b[39mmin_pnr\u001b[39;49m\u001b[39m'\u001b[39;49m: min_pnr,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/js0403/decode_lab_code/scripts_and_notebooks/projects/miniscope/134A_CNMFE_MESMERIZE.ipynb#X31sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m                                 \u001b[39m'\u001b[39;49m\u001b[39mnormalize_init\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39mFalse\u001b[39;49;00m,               \u001b[39m# just leave as is\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/js0403/decode_lab_code/scripts_and_notebooks/projects/miniscope/134A_CNMFE_MESMERIZE.ipynb#X31sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m                                 \u001b[39m'\u001b[39;49m\u001b[39mcenter_psf\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39mTrue\u001b[39;49;00m,                    \u001b[39m# True for 1p\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/js0403/decode_lab_code/scripts_and_notebooks/projects/miniscope/134A_CNMFE_MESMERIZE.ipynb#X31sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m                                 \u001b[39m'\u001b[39;49m\u001b[39mssub_B\u001b[39;49m\u001b[39m'\u001b[39;49m: ssub_B,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/js0403/decode_lab_code/scripts_and_notebooks/projects/miniscope/134A_CNMFE_MESMERIZE.ipynb#X31sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m                                 \u001b[39m'\u001b[39;49m\u001b[39mring_size_factor\u001b[39;49m\u001b[39m'\u001b[39;49m: ring_size_factor,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/js0403/decode_lab_code/scripts_and_notebooks/projects/miniscope/134A_CNMFE_MESMERIZE.ipynb#X31sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m                                 \u001b[39m'\u001b[39;49m\u001b[39mdel_duplicates\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39mTrue\u001b[39;49;00m,                \u001b[39m# whether to remove duplicates from initialization\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/js0403/decode_lab_code/scripts_and_notebooks/projects/miniscope/134A_CNMFE_MESMERIZE.ipynb#X31sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m                                 \u001b[39m'\u001b[39;49m\u001b[39mborder_pix\u001b[39;49m\u001b[39m'\u001b[39;49m: bord_px})                \u001b[39m# number of pixels to not consider in the borders)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/mescore/lib/python3.11/site-packages/caiman/source_extraction/cnmf/params.py:1072\u001b[0m, in \u001b[0;36mCNMFParams.change_params\u001b[0;34m(self, params_dict, verbose)\u001b[0m\n\u001b[1;32m   1070\u001b[0m     \u001b[39mif\u001b[39;00m flag:\n\u001b[1;32m   1071\u001b[0m         logging\u001b[39m.\u001b[39mwarning(\u001b[39m'\u001b[39m\u001b[39mNo parameter \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m found!\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(k))\n\u001b[0;32m-> 1072\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcheck_consistency()\n\u001b[1;32m   1073\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/mescore/lib/python3.11/site-packages/caiman/source_extraction/cnmf/params.py:919\u001b[0m, in \u001b[0;36mCNMFParams.check_consistency\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    917\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minit[\u001b[39m'\u001b[39m\u001b[39mgSiz\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    918\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minit[\u001b[39m'\u001b[39m\u001b[39mgSiz\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m [\u001b[39m2\u001b[39m\u001b[39m*\u001b[39mgs \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m \u001b[39mfor\u001b[39;00m gs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minit[\u001b[39m'\u001b[39m\u001b[39mgSig\u001b[39m\u001b[39m'\u001b[39m]]\n\u001b[0;32m--> 919\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minit[\u001b[39m'\u001b[39m\u001b[39mgSiz\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m([gs \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m \u001b[39mif\u001b[39;49;00m gs \u001b[39m%\u001b[39;49m \u001b[39m2\u001b[39;49m \u001b[39m==\u001b[39;49m \u001b[39m0\u001b[39;49m \u001b[39melse\u001b[39;49;00m gs \u001b[39mfor\u001b[39;49;00m gs \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minit[\u001b[39m'\u001b[39;49m\u001b[39mgSiz\u001b[39;49m\u001b[39m'\u001b[39;49m]])\n\u001b[1;32m    920\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpatch[\u001b[39m'\u001b[39m\u001b[39mrf\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    921\u001b[0m     \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39many(np\u001b[39m.\u001b[39marray(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpatch[\u001b[39m'\u001b[39m\u001b[39mrf\u001b[39m\u001b[39m'\u001b[39m]) \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minit[\u001b[39m'\u001b[39m\u001b[39mgSiz\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m]):\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "# parameters for source extraction and deconvolution\n",
    "p = 1               # order of the autoregressive system\n",
    "K = None            # upper bound on number of components per patch, in general None for CNMFE\n",
    "gSig = gSig_val  # expected half-width of neurons in pixels \n",
    "gSiz = 2*gSig_val + 1     # half-width of bounding box created around neurons during initialization\n",
    "merge_thr = .7      # merging threshold, max correlation allowed\n",
    "rf = 40             # half-size of the patches in pixels. e.g., if rf=40, patches are 80x80\n",
    "stride_cnmf = stride    # amount of overlap between the patches in pixels \n",
    "tsub = 2            # downsampling factor in time for initialization, increase if you have memory problems\n",
    "ssub = 1            # downsampling factor in space for initialization, increase if you have memory problems\n",
    "gnb = 0             # number of background components (rank) if positive, set to 0 for CNMFE\n",
    "low_rank_background = None  # None leaves background of each patch intact (use True if gnb>0)\n",
    "nb_patch = 0        # number of background components (rank) per patch (0 for CNMFE)\n",
    "min_corr = corr_pnr_inputs['min_corr']       # min peak value from correlation image\n",
    "min_pnr = corr_pnr_inputs['min_pnr']       # min peak to noise ration from PNR image\n",
    "ssub_B = 2          # additional downsampling factor in space for background (increase to 2 if slow)\n",
    "ring_size_factor = 1.4  # radius of ring is gSiz*ring_size_factor\n",
    "\n",
    "parameters.change_params(params_dict={'method_init': 'corr_pnr',  # use this for 1 photon\n",
    "                                'K': K,\n",
    "                                'gSig': gSig,\n",
    "                                'gSiz': gSiz,\n",
    "                                'merge_thr': merge_thr,\n",
    "                                'p': p,\n",
    "                                'tsub': tsub,\n",
    "                                'ssub': ssub,\n",
    "                                'rf': rf,\n",
    "                                'stride': stride_cnmf,\n",
    "                                'only_init': True,    # set it to True to run CNMF-E\n",
    "                                'nb': gnb,\n",
    "                                'nb_patch': nb_patch,\n",
    "                                'method_deconvolution': 'oasis',       # could use 'cvxpy' alternatively\n",
    "                                'low_rank_background': low_rank_background,\n",
    "                                'update_background_components': True,  # sometimes setting to False improve the results\n",
    "                                'min_corr': min_corr,\n",
    "                                'min_pnr': min_pnr,\n",
    "                                'normalize_init': False,               # just leave as is\n",
    "                                'center_psf': True,                    # True for 1p\n",
    "                                'ssub_B': ssub_B,\n",
    "                                'ring_size_factor': ring_size_factor,\n",
    "                                'del_duplicates': True,                # whether to remove duplicates from initialization\n",
    "                                'border_pix': bord_px})                # number of pixels to not consider in the borders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnmfe_model = cnmf.CNMF(n_processes=n_processes, \n",
    "                        dview=cluster, \n",
    "                        params=parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <h2 >CNMF-E: The Ring Model</h2>\n",
    "   <p>Background activity is very ill-behaved with 1p recordings: it often fluctuates locally and is much larger in magnitude than the neural signals we want to extract. In other words, the large-scale background model used for CNMF is not sufficient for most 1p data. Hence, Pengcheng Zhou and others came up with a localized model of background activity for CNMFE: CNMFE represents the background at each pixel as the weighted sum of activity from a circle (or ring) of pixels a certain distance from that pixel. The distance of this ring from the reference pixel is set by the <em>ring_size_factor</em> parameter. This more complex pixel-wise background model explains why CNMFE is computationally more expensive than CNMF, and also why it works better to mop up large-scale localized background noise to find the neurons in your 1p data.</p> \n",
    "    \n",
    "<p>When you set <em>gnb</em> in the CNMF model (usually to 1 or 2), you are setting the number of global background components to use. The fact that you can get away with so few is testament to how well-behaved the background activity is in 2p recordings compared to 1p. When we set <em>gnb</em> to 0 in Caiman, this is a flag telling Caiman's back end to switch to the ring model of the background activity.</p> \n",
    "\n",
    "For more details on CNMFE you can see the <a href=\"https://elifesciences.org/articles/28728\">original paper</a> and the <a href=\"https://elifesciences.org/articles/38173\">Caiman paper</a>. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key parameters for CNMFE\n",
    "The key parameters for CNMFE are slightly different than for CNMF, but with some overlap. As we'll see, because of the high levels of background activity, we can't initialize the same way as with CNMF. We have two new extremely important parameters directly related to initialization that come into play."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`rf` (int): *patch half-width*\n",
    "> `rf`, which stands for 'receptive field', is the half width of patches in pixels. The patch width is `2*rf + 1`. `rf` should be *at least* 3-4 times larger than the observed neuron diameter. The larger the patch size, the less parallelization will be used by Caiman. If `rf` is set to `None`, then CNMFE will be run on the entire field of view.\n",
    "\n",
    "`stride_cnmf (int)`: *patch overlap*\n",
    "> `stride_cnmf` is the overlap between patches in pixels (the actual overlap is `stride_cnmf + 1`). This should be at least the diameter of a neuron. The larger the overlap, the greater the computational load, but the results will be more accurate when stitching together results from different patches. This param should probably have been called 'overlap' instead of 'stride'.\n",
    "\n",
    "`gSig (int, int)`: *half-width of neurons*\n",
    "> `gSig` is roughly the half-width of neurons in your movie in pixels (height, width). It is the standard deviation of the mean-centered Gaussian used to filter the movie before initialization for CNMFE. It is related to the `gSiz` parameter, which is the size (in pixels) of a bounding box created around each seed pixel during initilialization. You will usually set `gSiz` to between `2*gSig` and `4*gSig` for CNMFE. \n",
    "\n",
    "`merge_thr (float)`: *merge threshold* \n",
    "> If the correlation between two spatially overlapping components is above `merge_thr`, they will be merged into one component. \n",
    "\n",
    "`min_corr` (float): *minimum correlation*\n",
    "> Pixels from neurons tend to be correlated with their neighbors. For initialization we select for pixels above a minimum correlation `min_corr`.  We discuss this more below.\n",
    "\n",
    "`min_pnr` (float): *minimum peak to noise ratio*\n",
    "> Set a threshoild peak-to-noise ratio. Pixels from neurons tend to have a high signal-to-noise ratio. For initialization we select for pixels above a minimum peak-to-noise-ratio `min_pnr`. We discuss this more below.\n",
    "\n",
    "As we did in `demo_pipeline.ipynb`, let's define a convenience function to get these key params for cnmfe so we can print them as we iteratively muck about in paramter space:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def key_params_cnmfe(cnmfe_model):\n",
    "    \"\"\"\n",
    "    Convenience function to return critical parameters given CNMFE estimator object.\n",
    "    Returns dict with values of rf, stride, gSig, gSiz, merge_threshold, min_corr, min_pnr\n",
    "    \n",
    "    Note: \n",
    "    gSiz is included because it depends on gSig and you want to make sure to change it when you change gSig.\n",
    "    These are not set in stone: tweak for your own needs!\n",
    "    \"\"\"\n",
    "    rf = cnmfe_model.params.patch['rf']\n",
    "    stride = cnmfe_model.params.patch['stride']\n",
    "    gSig = cnmfe_model.params.init['gSig']\n",
    "    gSiz = cnmfe_model.params.init['gSiz']\n",
    "    merge_thr = cnmfe_model.params.merging['merge_thr']\n",
    "    min_corr = cnmfe_model.params.init['min_corr']\n",
    "    min_pnr = cnmfe_model.params.init['min_pnr']\n",
    "    \n",
    "    \n",
    "    key_params = {'min_corr': min_corr,    \n",
    "                  'min_pnr': min_pnr,\n",
    "                  'rf': rf, \n",
    "                  'stride': stride,\n",
    "                  'gSig': gSig,\n",
    "                  'gSiz': gSiz,\n",
    "                  'merge_thr': merge_thr}\n",
    "    \n",
    "    return key_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect summary images and set parameters\n",
    "### Correlation-pnr plot\n",
    "For CNMFE, Caiman uses the correlation and peak-to-noise (PNR) ratio for initialization, which will both tend to be high in regions that contain neurons. Hence, we set a threshold for both quantitites to remove the low correlation/low pnr regions, and highlight the regions higher in both metrics, those regions most likely to contain neuronal activity. \n",
    "\n",
    "First, we calculate the correlation and pnr maps of the raw motion corrected movie after filtering with a mean-centered Gaussian with standard deviation `gSig` (for more information, see the sidebar below). These calculation can be computationally and memory demanding for large datasets, so we subsample if there are many thousands of frames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gSig)\n",
    "gsig_tmp = (3,3)\n",
    "correlation_image, peak_to_noise_ratio = cm.summary_images.correlation_pnr(images[::max(T//1000, 1)], # subsample if needed\n",
    "                                                                           gSig=gsig_tmp[0], # used for filter\n",
    "                                                                           swap_dim=False) # change swap dim if output looks weird, it is a problem with tiffile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/EricThomson/image_sandbox/main/images/bokeh_menu.jpg\" align=\"right\" width=\"200\"></img>\n",
    "Using `nb_inspect_correlation_pnr()`, you can inspect the correlation and PNR images to find reasonable threshold values for `min_corr` and `min_pnr`. You can adjust the range of values displayed in the plots shown below by choosing the Y-box select tool (third button from the left -- highlighted in yellow in the accompanying image) and selecting the desired region in the histograms to the right of each image. You can also use the pan button (first button on the left) to zoom/adjust the axis limits in the histogram to make it easier to see the limits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nb_inspect_correlation_pnr(corr, pnr, cmap='jet', num_bins=100):\n",
    "    \"\"\"\n",
    "    inspect correlation and pnr images to infer the min_corr, min_pnr for cnmfe\n",
    "\n",
    "    Args:\n",
    "        corr: ndarray\n",
    "            correlation image created with caiman.summary_images.correlation_pnr\n",
    "\n",
    "        pnr: ndarray\n",
    "            peak-to-noise image created with caiman.summary_images.correlation_pnr\n",
    "\n",
    "        cmap: string\n",
    "            colormap used for plotting corr and pnr images\n",
    "            For valid colormaps see https://holoviews.org/user_guide/Colormaps.html\n",
    "\n",
    "        num_bins: int\n",
    "            number of bins to use for plotting histogram of corr/pnr values\n",
    "\n",
    "    Returns:\n",
    "        Holoviews plot layout (typically just plots in notebook)\n",
    "    \"\"\"\n",
    "    import functools as fct\n",
    "    hv_corr = hv.Image(corr,\n",
    "                       vdims='corr',\n",
    "                       label='correlation').opts(cmap=cmap)\n",
    "    hv_pnr = hv.Image(pnr,\n",
    "                      vdims='pnr',\n",
    "                      label='pnr').opts(cmap=cmap)\n",
    "\n",
    "    def hist(im, rx, ry, num_bins=num_bins):\n",
    "        obj = im.select(x=rx, y=ry) if rx and ry else im\n",
    "        return hv.operation.histogram(obj, num_bins=num_bins)\n",
    "\n",
    "    str_corr = (hv.streams.RangeXY(source=hv_corr).rename(x_range='rx', y_range='ry'))\n",
    "    str_pnr = (hv.streams.RangeXY(source=hv_pnr).rename(x_range='rx', y_range='ry'))\n",
    "\n",
    "    hist_corr = hv.DynamicMap(\n",
    "        fct.partial(hist, im=hv_corr), streams=[str_corr])\n",
    "\n",
    "    hist_pnr = hv.DynamicMap(\n",
    "        fct.partial(hist, im=hv_pnr), streams=[str_pnr])\n",
    "\n",
    "    hv_layout = (hv_corr << hist_corr) + (hv_pnr << hist_pnr)\n",
    "\n",
    "    return hv_layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_inspect_correlation_pnr(correlation_image, peak_to_noise_ratio, cmap='inferno') # jet, fire are also good cmaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are looking for a couple of things in the above plot:\n",
    "1) Did we filter with a `gSig` value small enough so that we aren't blending different neurons together? To see what it is like when this happens, set `gsig_tmp` to `(6,6)` and inspect the above plots. \n",
    "2) More importantly, we want to find the threshold correlation and pnr values so that the *lower* threshold eliminates most of the noise and blood vessels from the plots, leaving behind as many of the neural pixels as possible. For this data it will be at a correlation value lower bound between 0.8 and 0.9, and and pnr lower bound somewhere between 10 and 20 (as with CNMF, there is no perfect value: it is often an iterative search, but keep in mind it is better to have false positives later than false negatives).\n",
    "\n",
    "You can tweak the parameters in the following cell (included are some values that are reasonable):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(key_params_cnmfe(cnmfe_model))\n",
    "\n",
    "gsig_new = gSig # unchanged\n",
    "min_corr_new  = 0.85 \n",
    "min_pnr_new = 12     \n",
    "\n",
    "cnmfe_model.params.change_params(params_dict={'gSig': gsig_new,\n",
    "                                              'min_corr': min_corr_new, \n",
    "                                              'min_pnr': min_pnr_new});\n",
    "\n",
    "print(key_params_cnmfe(cnmfe_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Caiman also includes a Qt-based corr-pnr viewer that some people prefer: `inspect_correlation_pnr()`. It provides what some say is a more intuitive interface than the notebook version above. It requires you to be in Qt mode (which you can enable using the cell magic `%matplotlib qt`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <h2>CNMFE initialization: More on correlation and peak-to-noise-ratio</h2>\n",
    "<img src=\"https://raw.githubusercontent.com/EricThomson/image_sandbox/main/images/mn_centered_gaussian.jpg\" align=\"right\" width=\"200\"></img>\n",
    "<p></p>How are correlation and peak-to-noise ratio actually calculated? First Caiman convolves the motion corrected movie with a <i>mean-centered Gaussian</i> (example to the right). The sigma of the Gaussian is <em>gSig</em>, and mean centering is turned on by setting <em>center_psf</em> to <em>True</em>. This mean centering creates a Gaussian with a positive peak in the middle of width <i>approximately</i> <em>gSig/2</em>, surrounded by a negative trench, and sets the outer edge to be zero. This preprocessing filter serves to highlight neuronal peaks and smooth away low-frequency background components.</p>\n",
    "\n",
    "<p>The function <em>correlation_pnr()</em> applies this mean-centered Gaussian to each frame of the motion corrected movie and returns the correlation image of that movie, as well as the peak-to-noise-ratio (PNR). The correlation image is the correlation of each pixel with its neighbors. The PNR is the ratio of the maximum magnitude at a pixel to the noise value at that pixel (it is a fast and rough measure of signal-to-noise). As mentioned above, both of these values tend to be higher in actual neurons, and the CNMFE initialization procedure is to set a threshold for both quantities, take their <i>product</i>, and use the peaks in this product map to find <i>seed pixels</i> for initialization of the CNMFE source separation algorithm.</p>\n",
    "\n",
    "<p>More details on the initialization procedure used here can be found in the <a href=\"https://elifesciences.org/articles/28728\">CNMFE paper</a>, or just by exploring the code.</p>         \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quilt plot for spatial parameters\n",
    "As discussed in `demo_pipeline.ipynb`, the other important paramters are those used for dividing the movie into patches for parallelization of source separation. The same processe is used for CNMFE. Namely, select `rf` and `stride` parameters so that many neurons fit in each patch, and at least one neuron fits in the overlap region between patches. You can visualize the patches using the `view_quilt()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate stride and overlap from parameters\n",
    "cnmfe_patch_width = cnmfe_model.params.patch['rf']*2 + 1\n",
    "cnmfe_patch_overlap = cnmfe_model.params.patch['stride'] + 1\n",
    "cnmfe_patch_stride = cnmfe_patch_width - cnmfe_patch_overlap\n",
    "print(f'Patch width: {cnmfe_patch_width} , Stride: {cnmfe_patch_stride}, Overlap: {cnmfe_patch_overlap}');\n",
    "\n",
    "# plot the patches\n",
    "patch_ax = view_quilt(correlation_image, \n",
    "                      cnmfe_patch_stride, \n",
    "                      cnmfe_patch_overlap, \n",
    "                      vmin=np.percentile(np.ravel(correlation_image),50), \n",
    "                      vmax=np.percentile(np.ravel(correlation_image),99.5),\n",
    "                      color='white',\n",
    "                      figsize=(4,4));\n",
    "patch_ax.set_title(f'CNMFE Patch Width {cnmfe_patch_width}, Overlap {cnmfe_patch_overlap}');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These patches and overlaps are large side, but that is ok: our main concern is that they not be too small. The `demo_notebook.ipynb` goes through in some detail adjusting the spatial parameters, as we did above for the initialization params. The process would be the same here if you needed to change the patch parameters for your data.\n",
    "\n",
    "Now that we are happy with our parameters, let's run the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the CNMF-E algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cnmfe_model.fit(images);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the algorithm creates an `estimates` class, which we discuss in detail in `demo_pipeline.ipynb`. The CNMFE `estimates` class includes almost all the same attributes as with CNMF, such as the neural spatial and temporal components `A` and `C`. \n",
    "\n",
    "It also includes the discovered model of background activity, which in this case is different from the CNMF model. For CNMF the background model is returned as low-rank matrices `b` and `f`. For CNMFE, the background model parameters are represented in the matrix `W` (the weights of the *ring model* for each pixel) as well as `b0` (the constant offset for each pixel). We will show how to reconstruct the background activity below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <h2>Run all of the above with one command</h2>\n",
    "    <p></p>It is possible to run the combined steps of motion correction, memory mapping, and cnmfe fitting using the <em>fit_file()</em> method. We recommend that you familiarize yourself with the various steps and the results of the various steps before using it.</p>\n",
    "    \n",
    "    cnmfe_all = cnmf.CNMF(n_processes, params=parameters, dview=cluster)\n",
    "    cnmfe_all.fit_file(motion_correct=motion_correct)\n",
    "    \n",
    "<p>It is most useful in the context of testing, or if sending jobs to a cluster.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Component Evaluation\n",
    "Source extraction typically produces many false positives. Our next step is quality control: separating the results into \"good\" and \"bad\" neurons using two different metrics (discussed in detail in `demo_notebook.ipynb`):\n",
    "\n",
    "- **Signal-to-noise ratio (SNR)**: a minimum SNR is set for the calcium transients (`min_SNR`).\n",
    "- **Spatial correlation**:  a minimum correlation is set between the shape of each component and the frames in the movie when that component is active (`rval_thr`). \n",
    "\n",
    "> Caiman does *not* use the CNN classifier to sort neurons based on shape for 1p data: the network was trained on 2p data. Hence, we set the `use_cnn` param to `False`. \n",
    "\n",
    "Here we set the two parameters and run `evaluate_components()` to see which pass muster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_SNR = 3            # SNR threshold\n",
    "rval_thr = 0.85    # spatial correlation threshold\n",
    "\n",
    "quality_params = {'min_SNR': min_SNR,\n",
    "                  'rval_thr': rval_thr,\n",
    "                  'use_cnn': False}\n",
    "cnmfe_model.params.change_params(params_dict=quality_params)\n",
    "\n",
    "cnmfe_model.estimates.evaluate_components(images, cnmfe_model.params, dview=cluster)\n",
    "\n",
    "print('*****')\n",
    "print(f\"Total number of components: {len(cnmfe_model.estimates.C)}\")\n",
    "print(f\"Number accepted: {len(cnmfe_model.estimates.idx_components)}\")\n",
    "print(f\"Number rejected: {len(cnmfe_model.estimates.idx_components_bad)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% plot contour plots of accepted and rejected components\n",
    "cnmfe_model.estimates.plot_contours_nb(img=correlation_image, \n",
    "                                       idx=cnmfe_model.estimates.idx_components);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These components look reasonable, if a bit large -- their centers are reasonable but the spatial footprints are quite spread out. If I were persuing this further, it would likely be helpful to re-run CNMFE reducing `gSiz` a bit, which can influence the overall \"spread\" of the neurons in space.\n",
    "\n",
    "View traces of accepted and rejected components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnmfe_model.estimates.nb_view_components(img=correlation_image, \n",
    "                                        idx=cnmfe_model.estimates.idx_components,\n",
    "                                        cmap='viridis', #gray\n",
    "                                        thr=.9); #increase to see full footprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rejected components\n",
    "cnmfe_model.estimates.nb_view_components(img=correlation_image, \n",
    "                                        idx=cnmfe_model.estimates.idx_components_bad,\n",
    "                                        cmap='viridis', #gray\n",
    "                                        denoised_color='red',\n",
    "                                        thr=0.8); #increase to see full footprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save and load results (optional)\n",
    "If you want to save your results so you don't have to run CNMFE again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results = True\n",
    "if save_results:\n",
    "    save_path =  r'demo_pipeline_cnmfe_results.hdf5'  # or add full/path/to/file.hdf5\n",
    "    cnmfe_model.estimates.Cn = correlation_image # squirrel away correlation image with cnmf object\n",
    "    cnmfe_model.save(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To load results and pick up where you left off (note this assumes you have done preliminaries like imports and started a cluster)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_results = True\n",
    "if load_results:\n",
    "    save_path =  r'demo_pipeline_cnmfe_results.hdf5'  # or add full/path/to/file.hdf5\n",
    "    cnmfe_model = load_CNMF(save_path, \n",
    "                                n_processes=num_processors_to_use, \n",
    "                                dview=cluster)\n",
    "    correlation_image = cnmfe_model.estimates.Cn\n",
    "    print(f\"Successfully loaded data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A few loose ends\n",
    "We have extracted the calcium traces C, spatial footprints A, and estimated spike counts S, which is the main goal with CNMF. But there are a few important things remaining. \n",
    "\n",
    "##  Deconvolution for 1p?\n",
    "While we haven't discussed deconvolution (the estimation of the spikes that generated the calcium traces in `C`), we suggest treating the spike counts returned for 1p data (in `estimates.S`) with CNMFE with some caution. Currently (as of Fall 2023) we are aware of no no ground-truth data that compares 1p recordings with actual spiking data. There is a *lot* of such data for 2p data, which allows for great comparison of different methods (for instance see [the Spikefinder paper](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1006157)).\n",
    "\n",
    "Because of this, most researchers analyze the calcium traces directly for 1p recordings (the data in `estimates.C`) or a normalized version of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract $\\Delta F/F$ values\n",
    "Currently in Caiman, we don't return a true dfof value for 1p data because Caiman normalizes to both the baseline fluorescence and background activity, and the background activity in 1p is so ill-behaved (as discussed above in the sidebar on the ring model). This is likely to change soon, but we currently only *detrend* the data (which will eliminate effects of photobleaching and other long-term artifacts) but do not normalize to baseline (which explains the warning you will see when you run the following):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cnmfe_model.estimates.F_dff is None:\n",
    "    print('Calculating estimates.F_dff')\n",
    "    cnmfe_model.estimates.detrend_df_f(quantileMin=8, \n",
    "                                      frames_window=250,\n",
    "                                      use_residuals=False);  # use denoised data\n",
    "else:\n",
    "    print(\"estimates.F_dff already defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View some different movie results\n",
    "As with CNMF, the CNMFE model of the original movie is:\n",
    "\n",
    "    original_movie = neural_activity + background + residual\n",
    "    \n",
    "The main between CNMF and CNMFE is the model of the background. We can reconstruct the neural movie as `AC` just as we did in `demo_pipeline.ipynb`. Unfortunately, reconstructing the background activity via the ring model is much more complicated for CNMFE, so we will just punt to a built-in function for that in what follows (`compute_background()`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case you are working from loaded data, recover the raw movie\n",
    "Yr, dims, num_frames = cm.load_memmap(cnmfe_model.mmap_file)\n",
    "images = np.reshape(Yr.T, [num_frames] + list(dims), order='F')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get model of neural activity and background activity (note for the neural model we are just including the accepted components):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_activity = cnmfe_model.estimates.A[:, cnmfe_model.estimates.idx_components] @\\\n",
    "                  cnmfe_model.estimates.C[cnmfe_model.estimates.idx_components, :]  # AC\n",
    "neural_movie = cm.movie(neural_activity).reshape(dims + (-1,), order='F').transpose([2, 0, 1])\n",
    "background_model = cnmfe_model.estimates.compute_background(Yr);  # build in function -- explore source code for details\n",
    "bg_movie = cm.movie(background_model).reshape(dims + (-1,), order='F').transpose([2, 0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To view just the movie of pure neural activity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsampling_ratio = 0.4 \n",
    "neural_movie.resize(fz=downsampling_ratio).play(gain=1.1,\n",
    "                                            q_max=99.5, \n",
    "                                            fr=20,\n",
    "                                            plot_text=True,\n",
    "                                            magnification=2,\n",
    "                                            do_loop=False,\n",
    "                                            backend='opencv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can view just the background model. You will see many regions that are constant such as blood vessels, but also lots of large-scale background flourescence, and some local activity which is is on spatial scales larger than `gSig`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downsampling_ratio = 0.8 \n",
    "bg_movie.resize(fz=downsampling_ratio).play(gain=1.1,\n",
    "                                            q_max=99.5, \n",
    "                                            fr=10,\n",
    "                                            plot_text=True,\n",
    "                                            magnification=2,\n",
    "                                            do_loop=False,\n",
    "                                            backend='opencv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the built-in `play_movie()` method to view the original movie, predicted movie, and the residual simultaneously as discussed in more detail in `demo_pipeline.ipynb`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# without background\n",
    "cnmfe_model.estimates.play_movie(images, \n",
    "                                 q_max=99.9, \n",
    "                                 magnification=2,\n",
    "                                 include_bck=False,\n",
    "                                 gain_res=5,\n",
    "                                 use_color=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A couple of things to note about that movie:\n",
    "- The middle panel of neural activity includes *all* components (accepted and rejected), so you will see some of the blood vessel \"activity\" that was discovered and later rejected.\n",
    "- The residual includes some activity that looks neural in origin. You can try playing with different params to get them (which do you think you would try?). The [Mesmerize](https://github.com/nel-lab/mesmerize-core) package is a great way to search parameter space and visualize results with more sophisticated visualization tools if you have a tricky data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean up open resourses\n",
    "Shut down server, close logger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm.stop_server(dview=cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shut down logger (otherwise will not be able to delete it)\n",
    "logging.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_logs = True\n",
    "logging_dir = cm.paths.get_tempdir() \n",
    "if delete_logs:\n",
    "    log_files = glob.glob(logging_dir + '\\\\demo_pipeline' + '*' + '.log')\n",
    "    for log_file in log_files:\n",
    "        print(f\"Deleting {log_file}\")\n",
    "        os.remove(log_file)\n",
    "else:\n",
    "    print(f\"If you want to inspect your logs they are in {logging_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
