{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html><head><meta content=\"text/html; charset=UTF-8\" http-equiv=\"content-type\"><style type=\"text/css\">ol</style></head><body class=\"c5\"><p class=\"c0 c4\"><span class=\"c3\"></span></p><p class=\"c2 title\" id=\"h.rrbabt268i6e\"><h1>CaImAn&rsquo;s Demo pipeline</h1></p><p class=\"c0\"><span class=\"c3\">This notebook will help to demonstrate the process of CaImAn and how it uses different functions to denoise, deconvolve and demix neurons from a two-photon Calcium Imaging dataset. The demo shows how to construct the `params`, `MotionCorrect` and `cnmf` objects and call the relevant functions. You can also run a large part of the pipeline with a single method (`cnmf.fit_file`). See inside for details.\n",
    "\n",
    "Dataset couresy of Sue Ann Koay and David Tank (Princeton University)\n",
    "\n",
    "This demo pertains to two photon data. For a complete analysis pipeline for one photon microendoscopic data see demo_pipeline_cnmfE.ipynb</span></p>\n",
    "<p class=\"c0\"><span class=\"c3\">More information can be found in the companion paper. </span></p>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f3/11w5x6bs32gd1xc4lh41qdnr0000gp/T/ipykernel_93918/1449603744.py:18: DeprecationWarning: `magic(...)` is deprecated since IPython 0.13 (warning added in 8.1), use run_line_magic(magic_name, parameter_s).\n",
      "  get_ipython().magic('load_ext autoreload')\n",
      "/var/folders/f3/11w5x6bs32gd1xc4lh41qdnr0000gp/T/ipykernel_93918/1449603744.py:19: DeprecationWarning: `magic(...)` is deprecated since IPython 0.13 (warning added in 8.1), use run_line_magic(magic_name, parameter_s).\n",
      "  get_ipython().magic('autoreload 2')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1002\">Loading BokehJS ...</span>\n",
       "    </div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\nconst JS_MIME_TYPE = 'application/javascript';\n  const HTML_MIME_TYPE = 'text/html';\n  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n  const CLASS_NAME = 'output_bokeh rendered_html';\n\n  /**\n   * Render data to the DOM node\n   */\n  function render(props, node) {\n    const script = document.createElement(\"script\");\n    node.appendChild(script);\n  }\n\n  /**\n   * Handle when an output is cleared or removed\n   */\n  function handleClearOutput(event, handle) {\n    const cell = handle.cell;\n\n    const id = cell.output_area._bokeh_element_id;\n    const server_id = cell.output_area._bokeh_server_id;\n    // Clean up Bokeh references\n    if (id != null && id in Bokeh.index) {\n      Bokeh.index[id].model.document.clear();\n      delete Bokeh.index[id];\n    }\n\n    if (server_id !== undefined) {\n      // Clean up Bokeh references\n      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n      cell.notebook.kernel.execute(cmd_clean, {\n        iopub: {\n          output: function(msg) {\n            const id = msg.content.text.trim();\n            if (id in Bokeh.index) {\n              Bokeh.index[id].model.document.clear();\n              delete Bokeh.index[id];\n            }\n          }\n        }\n      });\n      // Destroy server and session\n      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n      cell.notebook.kernel.execute(cmd_destroy);\n    }\n  }\n\n  /**\n   * Handle when a new output is added\n   */\n  function handleAddOutput(event, handle) {\n    const output_area = handle.output_area;\n    const output = handle.output;\n\n    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n      return\n    }\n\n    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n\n    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n      // store reference to embed id on output_area\n      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n    }\n    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n      const bk_div = document.createElement(\"div\");\n      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n      const script_attrs = bk_div.children[0].attributes;\n      for (let i = 0; i < script_attrs.length; i++) {\n        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n      }\n      // store reference to server id on output_area\n      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n    }\n  }\n\n  function register_renderer(events, OutputArea) {\n\n    function append_mime(data, metadata, element) {\n      // create a DOM node to render to\n      const toinsert = this.create_output_subarea(\n        metadata,\n        CLASS_NAME,\n        EXEC_MIME_TYPE\n      );\n      this.keyboard_manager.register_events(toinsert);\n      // Render to node\n      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n      render(props, toinsert[toinsert.length - 1]);\n      element.append(toinsert);\n      return toinsert\n    }\n\n    /* Handle when an output is cleared or removed */\n    events.on('clear_output.CodeCell', handleClearOutput);\n    events.on('delete.Cell', handleClearOutput);\n\n    /* Handle when a new output is added */\n    events.on('output_added.OutputArea', handleAddOutput);\n\n    /**\n     * Register the mime type and append_mime function with output_area\n     */\n    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n      /* Is output safe? */\n      safe: true,\n      /* Index of renderer in `output_area.display_order` */\n      index: 0\n    });\n  }\n\n  // register the mime type if in Jupyter Notebook environment and previously unregistered\n  if (root.Jupyter !== undefined) {\n    const events = require('base/js/events');\n    const OutputArea = require('notebook/js/outputarea').OutputArea;\n\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  }\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    const el = document.getElementById(\"1002\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.3.min.js\", \"https://unpkg.com/@holoviz/panel@0.14.4/dist/panel.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n          for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\nif (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"1002\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));",
      "application/vnd.bokehjs_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import bokeh.plotting as bpl\n",
    "import cv2\n",
    "import glob\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "try:\n",
    "    cv2.setNumThreads(0)\n",
    "except():\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    if __IPYTHON__:\n",
    "        # this is used for debugging purposes only. allows to reload classes\n",
    "        # when changed\n",
    "        get_ipython().magic('load_ext autoreload')\n",
    "        get_ipython().magic('autoreload 2')\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "import caiman as cm\n",
    "from caiman.motion_correction import MotionCorrect\n",
    "from caiman.source_extraction.cnmf import cnmf as cnmf\n",
    "from caiman.source_extraction.cnmf import params as params\n",
    "from caiman.utils.utils import download_demo\n",
    "from caiman.utils.visualization import plot_contours, nb_view_patches, nb_plot_contour\n",
    "bpl.output_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up logger (optional)\n",
    "You can log to a file using the filename parameter, or make the output more or less verbose by setting level to `logging.DEBUG`, `logging.INFO`, `logging.WARNING`, or `logging.ERROR`. A filename argument can also be passed to store the log file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format=\n",
    "                          \"%(relativeCreated)12d [%(filename)s:%(funcName)20s():%(lineno)s] [%(process)d] %(message)s\",\n",
    "                    # filename=\"/tmp/caiman.log\",\n",
    "                    level=logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select file(s) to be processed\n",
    "The `download_demo` function will download the specific file for you and return the complete path to the file which will be stored in your `caiman_data` directory. If you adapt this demo for your data make sure to pass the complete path to your file(s). Remember to pass the `fname` variable as a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = ['Sue_2x_3000_40_-46.tif']  # filename to be processed\n",
    "if fnames[0] in ['Sue_2x_3000_40_-46.tif', 'demoMovie.tif']:\n",
    "    fnames = [download_demo(fnames[0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Play the movie (optional)\n",
    "Play the movie (optional). This will require loading the movie in memory which in general is not needed by the pipeline. Displaying the movie uses the OpenCV library. Press `q` to close the video panel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  5.03it/s]\n"
     ]
    }
   ],
   "source": [
    "display_movie = True\n",
    "if display_movie:\n",
    "    m_orig = cm.load_movie_chain(fnames)\n",
    "    ds_ratio = 0.2\n",
    "    m_orig.resize(1, 1, ds_ratio).play(\n",
    "        q_max=99.5, fr=30, magnification=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup some parameters\n",
    "We set some parameters that are relevant to the file, and then parameters for motion correction, processing with CNMF and component quality evaluation. Note that the dataset `Sue_2x_3000_40_-46.tif` has been spatially downsampled by a factor of 2 and has a lower than usual spatial resolution (2um/pixel). As a result several parameters (`gSig, strides, max_shifts, rf, stride_cnmf`) have lower values (halved compared to a dataset with spatial resolution 1um/pixel)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset dependent parameters\n",
    "fr = 30                     # imaging rate in frames per second\n",
    "decay_time = 0.4            # length of a typical transient in seconds - neurons and non neurons\n",
    "\n",
    "# motion correction parameters\n",
    "strides = (48, 48)          # start a new patch for pw-rigid motion correction every x pixels\n",
    "overlaps = (24, 24)         # overlap between pathes (size of patch strides+overlaps)\n",
    "max_shifts = (6,6)          # maximum allowed rigid shifts (in pixels)\n",
    "max_deviation_rigid = 3     # maximum shifts deviation allowed for patch with respect to rigid shifts\n",
    "pw_rigid = True             # flag for performing non-rigid motion correction\n",
    "\n",
    "# parameters for source extraction and deconvolution\n",
    "p = 1                       # order of the autoregressive system\n",
    "gnb = 2                     # number of global background components\n",
    "merge_thr = 0.85            # merging threshold, max correlation allowed\n",
    "rf = 15                     # half-size of the patches in pixels. e.g., if rf=25, patches are 50x50\n",
    "stride_cnmf = 6             # amount of overlap between the patches in pixels\n",
    "K = 4                       # number of components per patch\n",
    "gSig = [4, 4]               # expected half size of neurons in pixels\n",
    "method_init = 'greedy_roi'  # initialization method (if analyzing dendritic data using 'sparse_nmf')\n",
    "ssub = 1                    # spatial subsampling during initialization\n",
    "tsub = 1                    # temporal subsampling during intialization\n",
    "\n",
    "# parameters for component evaluation\n",
    "min_SNR = 2.0               # signal to noise ratio for accepting a component\n",
    "rval_thr = 0.85              # space correlation threshold for accepting a component\n",
    "cnn_thr = 0.99              # threshold for CNN based classifier\n",
    "cnn_lowest = 0.1 # neurons with cnn probability lower than this value are rejected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a parameters object\n",
    "You can creating a parameters object by passing all the parameters as a single dictionary. Parameters not defined in the dictionary will assume their default values. The resulting `params` object is a collection of subdictionaries pertaining to the dataset to be analyzed `(params.data)`, motion correction `(params.motion)`, data pre-processing `(params.preprocess)`, initialization `(params.init)`, patch processing `(params.patch)`, spatial and temporal component `(params.spatial), (params.temporal)`, quality evaluation `(params.quality)` and online processing `(params.online)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "opts_dict = {'fnames': fnames,\n",
    "            'fr': fr,\n",
    "            'decay_time': decay_time,\n",
    "            'strides': strides,\n",
    "            'overlaps': overlaps,\n",
    "            'max_shifts': max_shifts,\n",
    "            'max_deviation_rigid': max_deviation_rigid,\n",
    "            'pw_rigid': pw_rigid,\n",
    "            'p': p,\n",
    "            'nb': gnb,\n",
    "            'rf': rf,\n",
    "            'K': K, \n",
    "            'gSig': gSig,\n",
    "            'stride': stride_cnmf,\n",
    "            'method_init': method_init,\n",
    "            'rolling_sum': True,\n",
    "            'only_init': True,\n",
    "            'ssub': ssub,\n",
    "            'tsub': tsub,\n",
    "            'merge_thr': merge_thr, \n",
    "            'min_SNR': min_SNR,\n",
    "            'rval_thr': rval_thr,\n",
    "            'use_cnn': True,\n",
    "            'min_cnn_thr': cnn_thr,\n",
    "            'cnn_lowest': cnn_lowest}\n",
    "\n",
    "opts = params.CNMFParams(params_dict=opts_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup a cluster\n",
    "To enable parallel processing a (local) cluster needs to be set up. This is done with a cell below. The variable `backend` determines the type of cluster used. The default value `'local'` uses the multiprocessing package. The `ipyparallel` option is also available. More information on these choices can be found [here](https://github.com/flatironinstitute/CaImAn/blob/master/CLUSTER.md). The resulting variable `dview` expresses the cluster option. If you use `dview=dview` in the downstream analysis then parallel processing will be used. If you use `dview=None` then no parallel processing will be employed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% start a cluster for parallel processing (if a cluster already exists it will be closed and a new session will be opened)\n",
    "if 'dview' in locals():\n",
    "    cm.stop_server(dview=dview)\n",
    "c, dview, n_processes = cm.cluster.setup_cluster(\n",
    "    backend='local', n_processes=None, single_thread=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the entire pipeline up to this point with one command\n",
    "It is possible to run the combined steps of motion correction, memory mapping, and cnmf fitting in one step as shown below. The command is commented out since the analysis has already been performed. It is recommended that you familiriaze yourself with the various steps and the results of the various steps before using it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      107941 [movies.py:      extract_shifts():339] [93918] Movie average is negative. Removing 1st percentile.\n",
      "      107942 [movies.py:      extract_shifts():357] [93918] Movie average is negative. Removing 1st percentile.\n",
      "      108010 [movies.py:      extract_shifts():339] [93918] Movie average is negative. Removing 1st percentile.\n",
      "      108012 [movies.py:      extract_shifts():357] [93918] Movie average is negative. Removing 1st percentile.\n",
      "      108075 [movies.py:      extract_shifts():339] [93918] Movie average is negative. Removing 1st percentile.\n",
      "      108077 [movies.py:      extract_shifts():357] [93918] Movie average is negative. Removing 1st percentile.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode mmap filename /Users/js0403/caiman_data/example_movies/Sue_2x_3000_40_-46_els__d1_170_d2_170_d3_1_order_F_frames_3000.mmap\n",
      "Decode mmap filename /Users/js0403/caiman_data/example_movies/Sue_2x_3000_40_-46_memmap_d1_170_d2_170_d3_1_order_C_frames_3000.mmap\n",
      "Decode mmap filename /Users/js0403/caiman_data/example_movies/Sue_2x_3000_40_-46_memmap_d1_170_d2_170_d3_1_order_C_frames_3000.mmapDecode mmap filename /Users/js0403/caiman_data/example_movies/Sue_2x_3000_40_-46_memmap_d1_170_d2_170_d3_1_order_C_frames_3000.mmap\n",
      "\n",
      "Decode mmap filename /Users/js0403/caiman_data/example_movies/Sue_2x_3000_40_-46_memmap_d1_170_d2_170_d3_1_order_C_frames_3000.mmap\n",
      "Decode mmap filename /Users/js0403/caiman_data/example_movies/Sue_2x_3000_40_-46_memmap_d1_170_d2_170_d3_1_order_C_frames_3000.mmap\n",
      "Decode mmap filename /Users/js0403/caiman_data/example_movies/Sue_2x_3000_40_-46_memmap_d1_170_d2_170_d3_1_order_C_frames_3000.mmap\n",
      "Decode mmap filename /Users/js0403/caiman_data/example_movies/Sue_2x_3000_40_-46_memmap_d1_170_d2_170_d3_1_order_C_frames_3000.mmap\n",
      "Decode mmap filename /Users/js0403/caiman_data/example_movies/Sue_2x_3000_40_-46_memmap_d1_170_d2_170_d3_1_order_C_frames_3000.mmap\n",
      "Decode mmap filename /Users/js0403/caiman_data/example_movies/Sue_2x_3000_40_-46_memmap_d1_170_d2_170_d3_1_order_C_frames_3000.mmap\n",
      "Decode mmap filename /Users/js0403/caiman_data/example_movies/Sue_2x_3000_40_-46_memmap_d1_170_d2_170_d3_1_order_C_frames_3000.mmap\n",
      "Decode mmap filename /Users/js0403/caiman_data/example_movies/Sue_2x_3000_40_-46_memmap_d1_170_d2_170_d3_1_order_C_frames_3000.mmap\n",
      "Decode mmap filename /Users/js0403/caiman_data/example_movies/Sue_2x_3000_40_-46_memmap_d1_170_d2_170_d3_1_order_C_frames_3000.mmap\n",
      "Decode mmap filename /Users/js0403/caiman_data/example_movies/Sue_2x_3000_40_-46_memmap_d1_170_d2_170_d3_1_order_C_frames_3000.mmap\n",
      "Decode mmap filename /Users/js0403/caiman_data/example_movies/Sue_2x_3000_40_-46_memmap_d1_170_d2_170_d3_1_order_C_frames_3000.mmap\n",
      "Decode mmap filename /Users/js0403/caiman_data/example_movies/Sue_2x_3000_40_-46_memmap_d1_170_d2_170_d3_1_order_C_frames_3000.mmap\n",
      "Decode mmap filename /Users/js0403/caiman_data/example_movies/Sue_2x_3000_40_-46_memmap_d1_170_d2_170_d3_1_order_C_frames_3000.mmap\n",
      "Decode mmap filename /Users/js0403/caiman_data/example_movies/Sue_2x_3000_40_-46_memmap_d1_170_d2_170_d3_1_order_C_frames_3000.mmap\n",
      "Decode mmap filename /Users/js0403/caiman_data/example_movies/Sue_2x_3000_40_-46_memmap_d1_170_d2_170_d3_1_order_C_frames_3000.mmap\n",
      "Decode mmap filename /Users/js0403/caiman_data/example_movies/Sue_2x_3000_40_-46_memmap_d1_170_d2_170_d3_1_order_C_frames_3000.mmap\n",
      "Decode mmap filename /Users/js0403/caiman_data/example_movies/Sue_2x_3000_40_-46_memmap_d1_170_d2_170_d3_1_order_C_frames_3000.mmap\n",
      "Decode mmap filename /Users/js0403/caiman_data/example_movies/Sue_2x_3000_40_-46_memmap_d1_170_d2_170_d3_1_order_C_frames_3000.mmap\n",
      "Decode mmap filename /Users/js0403/caiman_data/example_movies/Sue_2x_3000_40_-46_memmap_d1_170_d2_170_d3_1_order_C_frames_3000.mmap\n",
      "Decode mmap filename /Users/js0403/caiman_data/example_movies/Sue_2x_3000_40_-46_memmap_d1_170_d2_170_d3_1_order_C_frames_3000.mmap\n",
      "Decode mmap filename /Users/js0403/caiman_data/example_movies/Sue_2x_3000_40_-46_memmap_d1_170_d2_170_d3_1_order_C_frames_3000.mmap\n",
      "Decode mmap filename /Users/js0403/caiman_data/example_movies/Sue_2x_3000_40_-46_memmap_d1_170_d2_170_d3_1_order_C_frames_3000.mmap\n",
      "Decode mmap filename /Users/js0403/caiman_data/example_movies/Sue_2x_3000_40_-46_memmap_d1_170_d2_170_d3_1_order_C_frames_3000.mmap\n",
      "Decode mmap filename /Users/js0403/caiman_data/example_movies/Sue_2x_3000_40_-46_memmap_d1_170_d2_170_d3_1_order_C_frames_3000.mmap\n",
      "Decode mmap filename /Users/js0403/caiman_data/example_movies/Sue_2x_3000_40_-46_memmap_d1_170_d2_170_d3_1_order_C_frames_3000.mmap\n",
      "Decode mmap filename /Users/js0403/caiman_data/example_movies/Sue_2x_3000_40_-46_memmap_d1_170_d2_170_d3_1_order_C_frames_3000.mmap\n",
      "Decode mmap filename /Users/js0403/caiman_data/example_movies/Sue_2x_3000_40_-46_memmap_d1_170_d2_170_d3_1_order_C_frames_3000.mmap\n",
      "Decode mmap filename /Users/js0403/caiman_data/example_movies/Sue_2x_3000_40_-46_memmap_d1_170_d2_170_d3_1_order_C_frames_3000.mmap\n",
      "Decode mmap filename /Users/js0403/caiman_data/example_movies/Sue_2x_3000_40_-46_memmap_d1_170_d2_170_d3_1_order_C_frames_3000.mmap\n",
      "Decode mmap filename /Users/js0403/caiman_data/example_movies/Sue_2x_3000_40_-46_memmap_d1_170_d2_170_d3_1_order_C_frames_3000.mmap\n",
      "Decode mmap filename /Users/js0403/caiman_data/example_movies/Sue_2x_3000_40_-46_memmap_d1_170_d2_170_d3_1_order_C_frames_3000.mmap\n",
      "Decode mmap filename /Users/js0403/caiman_data/example_movies/Sue_2x_3000_40_-46_memmap_d1_170_d2_170_d3_1_order_C_frames_3000.mmap\n",
      "Decode mmap filename /Users/js0403/caiman_data/example_movies/Sue_2x_3000_40_-46_memmap_d1_170_d2_170_d3_1_order_C_frames_3000.mmap\n",
      "Decode mmap filename /Users/js0403/caiman_data/example_movies/Sue_2x_3000_40_-46_memmap_d1_170_d2_170_d3_1_order_C_frames_3000.mmap\n",
      "Decode mmap filename /Users/js0403/caiman_data/example_movies/Sue_2x_3000_40_-46_memmap_d1_170_d2_170_d3_1_order_C_frames_3000.mmap\n",
      "Decode mmap filename /Users/js0403/caiman_data/example_movies/Sue_2x_3000_40_-46_memmap_d1_170_d2_170_d3_1_order_C_frames_3000.mmap\n",
      "Decode mmap filename /Users/js0403/caiman_data/example_movies/Sue_2x_3000_40_-46_memmap_d1_170_d2_170_d3_1_order_C_frames_3000.mmap\n",
      "Decode mmap filename /Users/js0403/caiman_data/example_movies/Sue_2x_3000_40_-46_memmap_d1_170_d2_170_d3_1_order_C_frames_3000.mmap\n",
      "Decode mmap filename /Users/js0403/caiman_data/example_movies/Sue_2x_3000_40_-46_memmap_d1_170_d2_170_d3_1_order_C_frames_3000.mmap\n",
      "Decode mmap filename /Users/js0403/caiman_data/example_movies/Sue_2x_3000_40_-46_memmap_d1_170_d2_170_d3_1_order_C_frames_3000.mmap\n",
      "Decode mmap filename /Users/js0403/caiman_data/example_movies/Sue_2x_3000_40_-46_memmap_d1_170_d2_170_d3_1_order_C_frames_3000.mmap\n",
      "Decode mmap filename /Users/js0403/caiman_data/example_movies/Sue_2x_3000_40_-46_memmap_d1_170_d2_170_d3_1_order_C_frames_3000.mmap\n",
      "Decode mmap filename /Users/js0403/caiman_data/example_movies/Sue_2x_3000_40_-46_memmap_d1_170_d2_170_d3_1_order_C_frames_3000.mmap\n",
      "Decode mmap filename /Users/js0403/caiman_data/example_movies/Sue_2x_3000_40_-46_memmap_d1_170_d2_170_d3_1_order_C_frames_3000.mmap\n",
      "Decode mmap filename /Users/js0403/caiman_data/example_movies/Sue_2x_3000_40_-46_memmap_d1_170_d2_170_d3_1_order_C_frames_3000.mmap\n",
      "Decode mmap filename /Users/js0403/caiman_data/example_movies/Sue_2x_3000_40_-46_memmap_d1_170_d2_170_d3_1_order_C_frames_3000.mmap\n",
      "Decode mmap filename /Users/js0403/caiman_data/example_movies/Sue_2x_3000_40_-46_memmap_d1_170_d2_170_d3_1_order_C_frames_3000.mmap\n",
      "Decode mmap filename /Users/js0403/caiman_data/example_movies/Sue_2x_3000_40_-46_memmap_d1_170_d2_170_d3_1_order_C_frames_3000.mmap\n",
      "Decode mmap filename /Users/js0403/caiman_data/example_movies/Sue_2x_3000_40_-46_memmap_d1_170_d2_170_d3_1_order_C_frames_3000.mmap\n",
      "Decode mmap filename /Users/js0403/caiman_data/example_movies/Sue_2x_3000_40_-46_memmap_d1_170_d2_170_d3_1_order_C_frames_3000.mmap\n",
      "Decode mmap filename /Users/js0403/caiman_data/example_movies/Sue_2x_3000_40_-46_memmap_d1_170_d2_170_d3_1_order_C_frames_3000.mmap\n",
      "Decode mmap filename /Users/js0403/caiman_data/example_movies/Sue_2x_3000_40_-46_memmap_d1_170_d2_170_d3_1_order_C_frames_3000.mmap\n",
      "Decode mmap filename /Users/js0403/caiman_data/example_movies/Sue_2x_3000_40_-46_memmap_d1_170_d2_170_d3_1_order_C_frames_3000.mmap\n",
      "Decode mmap filename /Users/js0403/caiman_data/example_movies/Sue_2x_3000_40_-46_memmap_d1_170_d2_170_d3_1_order_C_frames_3000.mmap\n",
      "Decode mmap filename /Users/js0403/caiman_data/example_movies/Sue_2x_3000_40_-46_memmap_d1_170_d2_170_d3_1_order_C_frames_3000.mmap\n",
      "Decode mmap filename /Users/js0403/caiman_data/example_movies/Sue_2x_3000_40_-46_memmap_d1_170_d2_170_d3_1_order_C_frames_3000.mmap\n",
      "Decode mmap filename /Users/js0403/caiman_data/example_movies/Sue_2x_3000_40_-46_memmap_d1_170_d2_170_d3_1_order_C_frames_3000.mmap\n",
      "Decode mmap filename /Users/js0403/caiman_data/example_movies/Sue_2x_3000_40_-46_memmap_d1_170_d2_170_d3_1_order_C_frames_3000.mmap\n",
      "Decode mmap filename /Users/js0403/caiman_data/example_movies/Sue_2x_3000_40_-46_memmap_d1_170_d2_170_d3_1_order_C_frames_3000.mmap\n",
      "Decode mmap filename /Users/js0403/caiman_data/example_movies/Sue_2x_3000_40_-46_memmap_d1_170_d2_170_d3_1_order_C_frames_3000.mmap\n",
      "Decode mmap filename /Users/js0403/caiman_data/example_movies/Sue_2x_3000_40_-46_memmap_d1_170_d2_170_d3_1_order_C_frames_3000.mmap\n",
      "Decode mmap filename /Users/js0403/caiman_data/example_movies/Sue_2x_3000_40_-46_memmap_d1_170_d2_170_d3_1_order_C_frames_3000.mmap\n",
      "Decode mmap filename /Users/js0403/caiman_data/example_movies/Sue_2x_3000_40_-46_memmap_d1_170_d2_170_d3_1_order_C_frames_3000.mmap\n",
      "Decode mmap filename /Users/js0403/caiman_data/example_movies/Sue_2x_3000_40_-46_memmap_d1_170_d2_170_d3_1_order_C_frames_3000.mmap\n",
      "Decode mmap filename /Users/js0403/caiman_data/example_movies/Sue_2x_3000_40_-46_memmap_d1_170_d2_170_d3_1_order_C_frames_3000.mmap\n",
      "Decode mmap filename /Users/js0403/caiman_data/example_movies/Sue_2x_3000_40_-46_memmap_d1_170_d2_170_d3_1_order_C_frames_3000.mmap\n",
      "Decode mmap filename /Users/js0403/caiman_data/example_movies/Sue_2x_3000_40_-46_memmap_d1_170_d2_170_d3_1_order_C_frames_3000.mmap\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<caiman.source_extraction.cnmf.cnmf.CNMF at 0x1069a9750>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnm1 = cnmf.CNMF(n_processes, params=opts, dview=dview)\n",
    "cnm1.fit_file(motion_correct=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting the results\n",
    "Briefly inspect the results by plotting contours of identified components against correlation image.\n",
    "The results of the algorithm are stored in the object `cnm.estimates`. More information can be found in the definition of the `estimates` object and in the [wiki](https://github.com/flatironinstitute/CaImAn/wiki/Interpreting-Results)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% plot contours of found components\n",
    "Cn = cm.local_correlations(images.transpose(1,2,0))\n",
    "Cn[np.isnan(Cn)] = 0\n",
    "cnm.estimates.plot_contours_nb(img=Cn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-run (seeded) CNMF  on the full Field of View  \n",
    "You can re-run the CNMF algorithm seeded on just the selected components from the previous step. Be careful, because components rejected on the previous step will not be recovered here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "#%% RE-RUN seeded CNMF on accepted patches to refine and perform deconvolution \n",
    "cnm2 = cnm.refit(images, dview=dview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Component Evaluation\n",
    "\n",
    "The processing in patches creates several spurious components. These are filtered out by evaluating each component using three different criteria:\n",
    "\n",
    "- the shape of each component must be correlated with the data at the corresponding location within the FOV\n",
    "- a minimum peak SNR is required over the length of a transient\n",
    "- each shape passes a CNN based classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% COMPONENT EVALUATION\n",
    "# the components are evaluated in three ways:\n",
    "#   a) the shape of each component must be correlated with the data\n",
    "#   b) a minimum peak SNR is required over the length of a transient - SNR: signal:noise ratio\n",
    "#   c) each shape passes a CNN based classifier\n",
    "\n",
    "cnm2.estimates.evaluate_components(images, cnm2.params, dview=dview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot contours of selected and rejected components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% PLOT COMPONENTS\n",
    "cnm2.estimates.plot_contours_nb(img=Cn, idx=cnm2.estimates.idx_components)\n",
    "#plt.savefig('/Users/js0403/Documents/DECODE/caImAn/Results and Figs/fig_heatmap_avgMovie.eps', format='eps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View traces of accepted and rejected components. Note that if you get data rate error you can start Jupyter notebooks using:\n",
    "'jupyter notebook --NotebookApp.iopub_data_rate_limit=1.0e10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accepted components\n",
    "cnm2.estimates.nb_view_components(img=Cn, idx=cnm2.estimates.idx_components)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "# Here, I am playing with some ways to view the data to understand the variables a bit more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cnm2.estimates.idx_components\n",
    "# cn is the correlation matrix\n",
    "plt.imshow(Cn, cmap='hot', interpolation='nearest')\n",
    "plt.savefig('/Users/js0403/Documents/DECODE/caImAn/Results and Figs/fig_heatmap_avgMovie.eps', format='eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Extract DF/F values\n",
    "cnm2.estimates.detrend_df_f(quantileMin=8, frames_window=250)\n",
    "\n",
    "# lets get the dF/F\n",
    "dfF_all = cnm2.estimates.F_dff\n",
    "\n",
    "# get only good components\n",
    "dfF_good = dfF_all[cnm2.estimates.idx_components]\n",
    "\n",
    "# get total time\n",
    "totalTime = dfF_good.shape[1]/fr\n",
    "\n",
    "# make x-axis\n",
    "xAxis = np.linspace(0,totalTime,dfF_good.shape[1])\n",
    "\n",
    "\"\"\"\n",
    "fig = plt.figure(dpi=2000)\n",
    "ax = fig.add_subplot(dfF_good.shape[0],projection='3d')\n",
    "ax.set_xlabel('Time (sec)')\n",
    "ax.set_ylabel('norm. dF/F')\n",
    "ax.axis('off')\n",
    "for i in range(dfF_good.shape[0]):\n",
    "    line = ax.plot()\n",
    "\"\"\"\n",
    "\n",
    "fig = plt.figure(dpi=2000)\n",
    "gs  = fig.add_gridspec(dfF_good.shape[0], hspace=0)\n",
    "axs = gs.subplots(sharex=True, sharey=False)\n",
    "\n",
    "range(dfF_good.shape[0])\n",
    "for i in range(dfF_good.shape[0]):\n",
    "    axs[i].plot(xAxis,dfF_good[i,:],'k',linewidth=0.5)\n",
    "    axs[i].set_yticks([])\n",
    "    #axs[i].xticks(fontsize=8)       \n",
    "    if i != dfF_good.shape[0]-1:   \n",
    "        axs[i].axis('off')\n",
    "    else:\n",
    "        axs[i].set_frame_on(False)\n",
    "\n",
    "plt.savefig('/Users/js0403/Documents/DECODE/caImAn/Results and Figs/fig_dFf_subplots.eps', format='eps')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets do a heatmap now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(dfF_good, interpolation='nearest')\n",
    "plt.savefig('/Users/js0403/Documents/DECODE/caImAn/Results and Figs/fig_heatmap_dFf.eps', format='eps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rejected components\n",
    "if len(cnm2.estimates.idx_components_bad) > 0:\n",
    "    cnm2.estimates.nb_view_components(img=Cn, idx=cnm2.estimates.idx_components_bad)\n",
    "else:\n",
    "    print(\"No components were rejected.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract DF/F values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Extract DF/F values\n",
    "cnm2.estimates.detrend_df_f(quantileMin=8, frames_window=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select only high quality components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnm2.estimates.select_components(use_object=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnm2.estimates.nb_view_components(img=Cn, denoised_color='red')\n",
    "print('you may need to change the data rate to generate this one: use jupyter notebook --NotebookApp.iopub_data_rate_limit=1.0e10 before opening jupyter notebook')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Closing, saving, and creating denoised version\n",
    "### You can save an hdf5 file with all the fields of the cnmf object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results = False\n",
    "if save_results:\n",
    "    cnm2.save('analysis_results.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop cluster and clean up log files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% STOP CLUSTER and clean up log files\n",
    "cm.stop_server(dview=dview)\n",
    "log_files = glob.glob('*_LOG_*')\n",
    "for log_file in log_files:\n",
    "    os.remove(log_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View movie with the results\n",
    "We can inspect the denoised results by reconstructing the movie and playing alongside the original data and the resulting (amplified) residual movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnm2.estimates.play_movie(images, q_max=99.9, gain_res=2,\n",
    "                                  magnification=2,\n",
    "                                  bpx=border_to_0,\n",
    "                                  include_bck=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The denoised movie can also be explicitly constructed using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% reconstruct denoised movie\n",
    "denoised = cm.movie(cnm2.estimates.A.dot(cnm2.estimates.C) + \\\n",
    "                    cnm2.estimates.b.dot(cnm2.estimates.f)).reshape(dims + (-1,), order='F').transpose([2, 0, 1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
